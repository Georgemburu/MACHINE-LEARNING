{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n",
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "WARNING:tensorflow:From /home/george/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/george/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 80s 2ms/step - loss: 1.8805 - accuracy: 0.3226 - val_loss: 1.7789 - val_accuracy: 0.3422\n",
      "Q 870+61  T 931  \u001b[91m☒\u001b[0m 105 \n",
      "Q 475+32  T 507  \u001b[91m☒\u001b[0m 105 \n",
      "Q 86+971  T 1057 \u001b[91m☒\u001b[0m 109 \n",
      "Q 329+7   T 336  \u001b[91m☒\u001b[0m 10  \n",
      "Q 624+553 T 1177 \u001b[91m☒\u001b[0m 106 \n",
      "Q 85+861  T 946  \u001b[91m☒\u001b[0m 105 \n",
      "Q 296+1   T 297  \u001b[91m☒\u001b[0m 14  \n",
      "Q 260+591 T 851  \u001b[91m☒\u001b[0m 102 \n",
      "Q 745+49  T 794  \u001b[91m☒\u001b[0m 105 \n",
      "Q 0+797   T 797  \u001b[91m☒\u001b[0m 105 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 88s 2ms/step - loss: 1.7266 - accuracy: 0.3633 - val_loss: 1.6679 - val_accuracy: 0.3777\n",
      "Q 58+882  T 940  \u001b[91m☒\u001b[0m 902 \n",
      "Q 494+106 T 600  \u001b[91m☒\u001b[0m 914 \n",
      "Q 645+3   T 648  \u001b[91m☒\u001b[0m 566 \n",
      "Q 748+98  T 846  \u001b[91m☒\u001b[0m 902 \n",
      "Q 916+166 T 1082 \u001b[91m☒\u001b[0m 1222\n",
      "Q 115+69  T 184  \u001b[91m☒\u001b[0m 226 \n",
      "Q 199+551 T 750  \u001b[91m☒\u001b[0m 102 \n",
      "Q 613+923 T 1536 \u001b[91m☒\u001b[0m 1224\n",
      "Q 79+272  T 351  \u001b[91m☒\u001b[0m 804 \n",
      "Q 470+336 T 806  \u001b[91m☒\u001b[0m 114 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 119s 3ms/step - loss: 1.5960 - accuracy: 0.4024 - val_loss: 1.5211 - val_accuracy: 0.4277\n",
      "Q 615+249 T 864  \u001b[91m☒\u001b[0m 909 \n",
      "Q 96+122  T 218  \u001b[91m☒\u001b[0m 209 \n",
      "Q 79+980  T 1059 \u001b[91m☒\u001b[0m 1076\n",
      "Q 30+43   T 73   \u001b[91m☒\u001b[0m 44  \n",
      "Q 326+615 T 941  \u001b[91m☒\u001b[0m 909 \n",
      "Q 663+97  T 760  \u001b[91m☒\u001b[0m 702 \n",
      "Q 22+43   T 65   \u001b[91m☒\u001b[0m 24  \n",
      "Q 507+34  T 541  \u001b[91m☒\u001b[0m 549 \n",
      "Q 15+505  T 520  \u001b[91m☒\u001b[0m 569 \n",
      "Q 313+465 T 778  \u001b[91m☒\u001b[0m 609 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 140s 3ms/step - loss: 1.4534 - accuracy: 0.4529 - val_loss: 1.3917 - val_accuracy: 0.4834\n",
      "Q 732+48  T 780  \u001b[91m☒\u001b[0m 811 \n",
      "Q 786+392 T 1178 \u001b[91m☒\u001b[0m 1101\n",
      "Q 88+677  T 765  \u001b[91m☒\u001b[0m 842 \n",
      "Q 259+4   T 263  \u001b[91m☒\u001b[0m 238 \n",
      "Q 82+59   T 141  \u001b[91m☒\u001b[0m 119 \n",
      "Q 260+591 T 851  \u001b[91m☒\u001b[0m 902 \n",
      "Q 435+946 T 1381 \u001b[91m☒\u001b[0m 1322\n",
      "Q 27+928  T 955  \u001b[91m☒\u001b[0m 901 \n",
      "Q 2+881   T 883  \u001b[91m☒\u001b[0m 888 \n",
      "Q 545+34  T 579  \u001b[91m☒\u001b[0m 588 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 171s 4ms/step - loss: 1.3124 - accuracy: 0.5077 - val_loss: 1.2643 - val_accuracy: 0.5231\n",
      "Q 3+898   T 901  \u001b[91m☒\u001b[0m 997 \n",
      "Q 5+373   T 378  \u001b[91m☒\u001b[0m 376 \n",
      "Q 998+145 T 1143 \u001b[91m☒\u001b[0m 1041\n",
      "Q 2+469   T 471  \u001b[91m☒\u001b[0m 466 \n",
      "Q 753+314 T 1067 \u001b[91m☒\u001b[0m 900 \n",
      "Q 60+633  T 693  \u001b[91m☒\u001b[0m 672 \n",
      "Q 34+312  T 346  \u001b[92m☑\u001b[0m 346 \n",
      "Q 93+23   T 116  \u001b[91m☒\u001b[0m 119 \n",
      "Q 719+57  T 776  \u001b[91m☒\u001b[0m 785 \n",
      "Q 196+9   T 205  \u001b[91m☒\u001b[0m 199 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 124s 3ms/step - loss: 1.1992 - accuracy: 0.5543 - val_loss: 1.1511 - val_accuracy: 0.5752\n",
      "Q 21+317  T 338  \u001b[91m☒\u001b[0m 242 \n",
      "Q 1+852   T 853  \u001b[91m☒\u001b[0m 822 \n",
      "Q 90+50   T 140  \u001b[91m☒\u001b[0m 144 \n",
      "Q 991+629 T 1620 \u001b[91m☒\u001b[0m 1674\n",
      "Q 20+699  T 719  \u001b[91m☒\u001b[0m 692 \n",
      "Q 648+440 T 1088 \u001b[91m☒\u001b[0m 1103\n",
      "Q 210+826 T 1036 \u001b[91m☒\u001b[0m 1000\n",
      "Q 114+58  T 172  \u001b[92m☑\u001b[0m 172 \n",
      "Q 86+283  T 369  \u001b[91m☒\u001b[0m 352 \n",
      "Q 42+380  T 422  \u001b[91m☒\u001b[0m 412 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 77s 2ms/step - loss: 1.0933 - accuracy: 0.5967 - val_loss: 1.0514 - val_accuracy: 0.6128\n",
      "Q 317+597 T 914  \u001b[91m☒\u001b[0m 904 \n",
      "Q 7+470   T 477  \u001b[92m☑\u001b[0m 477 \n",
      "Q 10+20   T 30   \u001b[91m☒\u001b[0m 36  \n",
      "Q 776+570 T 1346 \u001b[91m☒\u001b[0m 1364\n",
      "Q 63+16   T 79   \u001b[91m☒\u001b[0m 60  \n",
      "Q 328+34  T 362  \u001b[91m☒\u001b[0m 363 \n",
      "Q 800+71  T 871  \u001b[91m☒\u001b[0m 860 \n",
      "Q 430+96  T 526  \u001b[91m☒\u001b[0m 518 \n",
      "Q 541+930 T 1471 \u001b[91m☒\u001b[0m 1408\n",
      "Q 123+54  T 177  \u001b[91m☒\u001b[0m 176 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 75s 2ms/step - loss: 1.0095 - accuracy: 0.6313 - val_loss: 0.9770 - val_accuracy: 0.6457\n",
      "Q 98+743  T 841  \u001b[91m☒\u001b[0m 834 \n",
      "Q 834+346 T 1180 \u001b[91m☒\u001b[0m 1164\n",
      "Q 553+412 T 965  \u001b[91m☒\u001b[0m 954 \n",
      "Q 567+7   T 574  \u001b[91m☒\u001b[0m 575 \n",
      "Q 193+14  T 207  \u001b[91m☒\u001b[0m 203 \n",
      "Q 998+706 T 1704 \u001b[91m☒\u001b[0m 1676\n",
      "Q 1+30    T 31   \u001b[91m☒\u001b[0m 36  \n",
      "Q 84+306  T 390  \u001b[91m☒\u001b[0m 391 \n",
      "Q 824+889 T 1713 \u001b[91m☒\u001b[0m 1671\n",
      "Q 3+597   T 600  \u001b[91m☒\u001b[0m 505 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 73s 2ms/step - loss: 0.9509 - accuracy: 0.6531 - val_loss: 0.9332 - val_accuracy: 0.6579\n",
      "Q 687+562 T 1249 \u001b[91m☒\u001b[0m 1233\n",
      "Q 45+232  T 277  \u001b[91m☒\u001b[0m 278 \n",
      "Q 75+63   T 138  \u001b[91m☒\u001b[0m 139 \n",
      "Q 704+871 T 1575 \u001b[91m☒\u001b[0m 1511\n",
      "Q 728+93  T 821  \u001b[91m☒\u001b[0m 811 \n",
      "Q 502+79  T 581  \u001b[91m☒\u001b[0m 589 \n",
      "Q 354+121 T 475  \u001b[91m☒\u001b[0m 591 \n",
      "Q 729+217 T 946  \u001b[91m☒\u001b[0m 979 \n",
      "Q 428+680 T 1108 \u001b[91m☒\u001b[0m 1111\n",
      "Q 50+310  T 360  \u001b[91m☒\u001b[0m 365 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 100s 2ms/step - loss: 0.9049 - accuracy: 0.6704 - val_loss: 0.8862 - val_accuracy: 0.6780\n",
      "Q 88+171  T 259  \u001b[91m☒\u001b[0m 254 \n",
      "Q 280+12  T 292  \u001b[91m☒\u001b[0m 291 \n",
      "Q 927+5   T 932  \u001b[91m☒\u001b[0m 933 \n",
      "Q 291+296 T 587  \u001b[91m☒\u001b[0m 469 \n",
      "Q 204+897 T 1101 \u001b[91m☒\u001b[0m 1043\n",
      "Q 516+823 T 1339 \u001b[91m☒\u001b[0m 1366\n",
      "Q 19+6    T 25   \u001b[91m☒\u001b[0m 28  \n",
      "Q 398+894 T 1292 \u001b[91m☒\u001b[0m 1268\n",
      "Q 79+800  T 879  \u001b[92m☑\u001b[0m 879 \n",
      "Q 275+66  T 341  \u001b[91m☒\u001b[0m 344 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 91s 2ms/step - loss: 0.8647 - accuracy: 0.6835 - val_loss: 0.8505 - val_accuracy: 0.6861\n",
      "Q 25+631  T 656  \u001b[92m☑\u001b[0m 656 \n",
      "Q 911+672 T 1583 \u001b[91m☒\u001b[0m 1576\n",
      "Q 588+641 T 1229 \u001b[91m☒\u001b[0m 1233\n",
      "Q 266+16  T 282  \u001b[91m☒\u001b[0m 280 \n",
      "Q 626+771 T 1397 \u001b[91m☒\u001b[0m 1407\n",
      "Q 174+8   T 182  \u001b[91m☒\u001b[0m 180 \n",
      "Q 274+315 T 589  \u001b[91m☒\u001b[0m 606 \n",
      "Q 5+750   T 755  \u001b[91m☒\u001b[0m 756 \n",
      "Q 715+43  T 758  \u001b[91m☒\u001b[0m 767 \n",
      "Q 23+85   T 108  \u001b[91m☒\u001b[0m 100 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 96s 2ms/step - loss: 0.8214 - accuracy: 0.6990 - val_loss: 0.8051 - val_accuracy: 0.7061\n",
      "Q 981+990 T 1971 \u001b[91m☒\u001b[0m 1888\n",
      "Q 41+990  T 1031 \u001b[91m☒\u001b[0m 1037\n",
      "Q 76+528  T 604  \u001b[91m☒\u001b[0m 602 \n",
      "Q 700+801 T 1501 \u001b[91m☒\u001b[0m 1421\n",
      "Q 254+63  T 317  \u001b[91m☒\u001b[0m 311 \n",
      "Q 26+5    T 31   \u001b[91m☒\u001b[0m 28  \n",
      "Q 178+172 T 350  \u001b[91m☒\u001b[0m 344 \n",
      "Q 776+72  T 848  \u001b[91m☒\u001b[0m 846 \n",
      "Q 40+973  T 1013 \u001b[91m☒\u001b[0m 1010\n",
      "Q 69+358  T 427  \u001b[91m☒\u001b[0m 432 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 116s 3ms/step - loss: 0.7763 - accuracy: 0.7198 - val_loss: 0.7666 - val_accuracy: 0.7207\n",
      "Q 30+924  T 954  \u001b[91m☒\u001b[0m 955 \n",
      "Q 71+167  T 238  \u001b[91m☒\u001b[0m 239 \n",
      "Q 466+85  T 551  \u001b[91m☒\u001b[0m 556 \n",
      "Q 298+617 T 915  \u001b[91m☒\u001b[0m 900 \n",
      "Q 99+68   T 167  \u001b[91m☒\u001b[0m 162 \n",
      "Q 22+190  T 212  \u001b[91m☒\u001b[0m 219 \n",
      "Q 4+561   T 565  \u001b[91m☒\u001b[0m 568 \n",
      "Q 875+301 T 1176 \u001b[91m☒\u001b[0m 1183\n",
      "Q 831+3   T 834  \u001b[91m☒\u001b[0m 835 \n",
      "Q 220+44  T 264  \u001b[91m☒\u001b[0m 266 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 116s 3ms/step - loss: 0.7436 - accuracy: 0.7322 - val_loss: 0.7377 - val_accuracy: 0.7330\n",
      "Q 93+874  T 967  \u001b[91m☒\u001b[0m 961 \n",
      "Q 236+592 T 828  \u001b[91m☒\u001b[0m 830 \n",
      "Q 69+358  T 427  \u001b[91m☒\u001b[0m 422 \n",
      "Q 49+301  T 350  \u001b[91m☒\u001b[0m 351 \n",
      "Q 14+617  T 631  \u001b[91m☒\u001b[0m 630 \n",
      "Q 3+945   T 948  \u001b[91m☒\u001b[0m 941 \n",
      "Q 19+281  T 300  \u001b[91m☒\u001b[0m 307 \n",
      "Q 926+82  T 1008 \u001b[91m☒\u001b[0m 1001\n",
      "Q 921+66  T 987  \u001b[91m☒\u001b[0m 981 \n",
      "Q 830+274 T 1104 \u001b[91m☒\u001b[0m 1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 122s 3ms/step - loss: 0.7076 - accuracy: 0.7443 - val_loss: 0.6961 - val_accuracy: 0.7483\n",
      "Q 160+3   T 163  \u001b[92m☑\u001b[0m 163 \n",
      "Q 95+383  T 478  \u001b[91m☒\u001b[0m 471 \n",
      "Q 1+849   T 850  \u001b[91m☒\u001b[0m 849 \n",
      "Q 516+96  T 612  \u001b[91m☒\u001b[0m 613 \n",
      "Q 777+391 T 1168 \u001b[91m☒\u001b[0m 1179\n",
      "Q 266+224 T 490  \u001b[91m☒\u001b[0m 486 \n",
      "Q 985+778 T 1763 \u001b[92m☑\u001b[0m 1763\n",
      "Q 27+36   T 63   \u001b[91m☒\u001b[0m 62  \n",
      "Q 385+402 T 787  \u001b[91m☒\u001b[0m 786 \n",
      "Q 0+445   T 445  \u001b[91m☒\u001b[0m 443 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 130s 3ms/step - loss: 0.6564 - accuracy: 0.7616 - val_loss: 0.6242 - val_accuracy: 0.7695\n",
      "Q 455+77  T 532  \u001b[91m☒\u001b[0m 533 \n",
      "Q 782+945 T 1727 \u001b[92m☑\u001b[0m 1727\n",
      "Q 252+360 T 612  \u001b[92m☑\u001b[0m 612 \n",
      "Q 123+54  T 177  \u001b[92m☑\u001b[0m 177 \n",
      "Q 878+30  T 908  \u001b[91m☒\u001b[0m 909 \n",
      "Q 500+874 T 1374 \u001b[91m☒\u001b[0m 1372\n",
      "Q 31+134  T 165  \u001b[91m☒\u001b[0m 167 \n",
      "Q 67+983  T 1050 \u001b[92m☑\u001b[0m 1050\n",
      "Q 15+73   T 88   \u001b[91m☒\u001b[0m 87  \n",
      "Q 843+674 T 1517 \u001b[91m☒\u001b[0m 1518\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 123s 3ms/step - loss: 0.5488 - accuracy: 0.8032 - val_loss: 0.4985 - val_accuracy: 0.8175\n",
      "Q 467+951 T 1418 \u001b[91m☒\u001b[0m 1429\n",
      "Q 437+41  T 478  \u001b[92m☑\u001b[0m 478 \n",
      "Q 386+54  T 440  \u001b[91m☒\u001b[0m 430 \n",
      "Q 337+21  T 358  \u001b[92m☑\u001b[0m 358 \n",
      "Q 20+699  T 719  \u001b[92m☑\u001b[0m 719 \n",
      "Q 453+369 T 822  \u001b[91m☒\u001b[0m 813 \n",
      "Q 69+688  T 757  \u001b[91m☒\u001b[0m 756 \n",
      "Q 75+457  T 532  \u001b[91m☒\u001b[0m 531 \n",
      "Q 435+3   T 438  \u001b[92m☑\u001b[0m 438 \n",
      "Q 27+194  T 221  \u001b[91m☒\u001b[0m 223 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 115s 3ms/step - loss: 0.4321 - accuracy: 0.8529 - val_loss: 0.3998 - val_accuracy: 0.8584\n",
      "Q 974+44  T 1018 \u001b[91m☒\u001b[0m 1017\n",
      "Q 59+79   T 138  \u001b[91m☒\u001b[0m 136 \n",
      "Q 598+14  T 612  \u001b[91m☒\u001b[0m 613 \n",
      "Q 771+855 T 1626 \u001b[92m☑\u001b[0m 1626\n",
      "Q 66+270  T 336  \u001b[92m☑\u001b[0m 336 \n",
      "Q 53+725  T 778  \u001b[92m☑\u001b[0m 778 \n",
      "Q 264+73  T 337  \u001b[92m☑\u001b[0m 337 \n",
      "Q 207+611 T 818  \u001b[92m☑\u001b[0m 818 \n",
      "Q 0+274   T 274  \u001b[91m☒\u001b[0m 276 \n",
      "Q 22+223  T 245  \u001b[91m☒\u001b[0m 246 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 120s 3ms/step - loss: 0.3270 - accuracy: 0.8992 - val_loss: 0.2877 - val_accuracy: 0.9200\n",
      "Q 41+48   T 89   \u001b[92m☑\u001b[0m 89  \n",
      "Q 23+560  T 583  \u001b[92m☑\u001b[0m 583 \n",
      "Q 861+666 T 1527 \u001b[92m☑\u001b[0m 1527\n",
      "Q 36+289  T 325  \u001b[92m☑\u001b[0m 325 \n",
      "Q 613+923 T 1536 \u001b[92m☑\u001b[0m 1536\n",
      "Q 606+491 T 1097 \u001b[91m☒\u001b[0m 1096\n",
      "Q 7+298   T 305  \u001b[92m☑\u001b[0m 305 \n",
      "Q 377+67  T 444  \u001b[92m☑\u001b[0m 444 \n",
      "Q 189+35  T 224  \u001b[92m☑\u001b[0m 224 \n",
      "Q 74+34   T 108  \u001b[92m☑\u001b[0m 108 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 124s 3ms/step - loss: 0.2456 - accuracy: 0.9338 - val_loss: 0.2301 - val_accuracy: 0.9344\n",
      "Q 73+838  T 911  \u001b[92m☑\u001b[0m 911 \n",
      "Q 465+5   T 470  \u001b[92m☑\u001b[0m 470 \n",
      "Q 769+55  T 824  \u001b[92m☑\u001b[0m 824 \n",
      "Q 26+361  T 387  \u001b[92m☑\u001b[0m 387 \n",
      "Q 398+894 T 1292 \u001b[91m☒\u001b[0m 1282\n",
      "Q 283+2   T 285  \u001b[92m☑\u001b[0m 285 \n",
      "Q 685+3   T 688  \u001b[91m☒\u001b[0m 687 \n",
      "Q 76+652  T 728  \u001b[92m☑\u001b[0m 728 \n",
      "Q 577+955 T 1532 \u001b[92m☑\u001b[0m 1532\n",
      "Q 75+38   T 113  \u001b[92m☑\u001b[0m 113 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 135s 3ms/step - loss: 0.1931 - accuracy: 0.9522 - val_loss: 0.2466 - val_accuracy: 0.9311\n",
      "Q 764+79  T 843  \u001b[92m☑\u001b[0m 843 \n",
      "Q 300+1   T 301  \u001b[92m☑\u001b[0m 301 \n",
      "Q 40+397  T 437  \u001b[92m☑\u001b[0m 437 \n",
      "Q 64+601  T 665  \u001b[91m☒\u001b[0m 655 \n",
      "Q 324+38  T 362  \u001b[92m☑\u001b[0m 362 \n",
      "Q 831+330 T 1161 \u001b[91m☒\u001b[0m 1261\n",
      "Q 780+341 T 1121 \u001b[91m☒\u001b[0m 1221\n",
      "Q 79+272  T 351  \u001b[92m☑\u001b[0m 351 \n",
      "Q 588+641 T 1229 \u001b[91m☒\u001b[0m 1239\n",
      "Q 66+556  T 622  \u001b[92m☑\u001b[0m 622 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "12928/45000 [=======>......................] - ETA: 1:17 - loss: 0.1659 - accuracy: 0.9618"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bc976ad4d312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    164\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
