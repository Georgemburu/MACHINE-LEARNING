{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(add) tf.Tensor(3, shape=(), dtype=int32)\n",
      "(add) tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "(square) tf.Tensor(25, shape=(), dtype=int32)\n",
      "(reduce_sum) tf.Tensor(6, shape=(), dtype=int32)\n",
      "##########\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Tensors\n",
    "## -> is a multi-dimensional array.\n",
    "# operations\n",
    "print('(add)',tf.add(1,2))\n",
    "print('(add)',tf.add([1,2],[3,4]))\n",
    "print('(square)',tf.square(5))\n",
    "print('(reduce_sum)',tf.reduce_sum([1,2,3]))\n",
    "print('#'*10)\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2)+ tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB. Each tf.Tensor has a shape and a dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]],[[2,3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIFFERENCE BETWEEN NUMPY arrays AND tf.Tensors:\n",
    "#################################\n",
    "# 1. Tensors can be backed by accelerator memory (like GPU, TPU)\n",
    "# 2. Tensors are immutable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And Numpy operations conver Tensors to numpy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The .numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "# Numpy Compatibility\n",
    "#######################################\n",
    "# Converting between a TensorFlow tf.Tensors and Numpy ndarray\n",
    "###################################\n",
    "# TensorFLow operations automatically convert Numpy ndarrays\n",
    "# to Tensors\n",
    "# Numpy operations automatically convert Tensors to Numpy ndarrays\n",
    "##################################\n",
    "# Tensors are explicitly converted to Numpy ndarrays using their\n",
    "# (.numpy()) method.\n",
    "##\n",
    "import numpy as np\n",
    "ndarray = np.ones([3,3])\n",
    "\n",
    "print('TensorFlow operations convert numpy arrays to Tensors',\n",
    "      'automatically')\n",
    "tensor = tf.multiply(ndarray,42)\n",
    "print(tensor)\n",
    "##################\n",
    "print('And Numpy operations conver Tensors to numpy arrays automatically')\n",
    "print(np.add(tensor,1))\n",
    "#####################\n",
    "print('The .numpy() method explicitly converts a Tensor to a numpy array')\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available:\n",
      "[]\n",
      "Is the Tensor on GPU #0. \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# GPU acceleration\n",
    "# Tensors produced by an operation are typically backed by the\n",
    "# memory of the device on which the operation executed#\n",
    "# e.g\n",
    "x = tf.random.uniform([3,3])\n",
    "print('Is there a GPU available:')\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print('Is the Tensor on GPU #0. ')\n",
    "print(x.device.endswith('GPU:0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device Names\n",
    "#####################\n",
    "# The (Tensor.device) property provides a fully qualified \n",
    "# string name of device hosting the contents of the tensor\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on CPU:\n",
      "10 loops: 305.05ms\n"
     ]
    }
   ],
   "source": [
    "# Explicit Device Placement\n",
    "###########################\n",
    "# In TensorFlow, placement refers to how individuals operations\n",
    "# are assigned (placed on) a device for execution.\n",
    "########\n",
    "# When there is no explicit guidance provided, TensorFlow \n",
    "# automatically decides which devie to execute an operation \n",
    "# and copies tensors to that device.\n",
    "###########\n",
    "# Whowever, TensorFlow operations can be explicitly placed\n",
    "# on  specific devices using the (tf.device) context manager,\n",
    "## e.g\n",
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "    start = time.time()\n",
    "    for loop in range(10):\n",
    "        tf.matmul(x,x)\n",
    "        \n",
    "    result = time.time()-start\n",
    "    print('10 loops: {:0.2f}ms'.format(1000*result))\n",
    "    \n",
    "# Force execution on CPU\n",
    "print('on CPU:')\n",
    "with tf.device('CPU:0'):\n",
    "    X = tf.random_uniform([1000, 1000])\n",
    "    assert x.device.endswith('CPU:0')\n",
    "    time_matmul(x)\n",
    "\n",
    "# Force execution on GPU #0  if available\n",
    "if(tf.config.experimental.list_physical_devices('GPU')):\n",
    "    print('On GPU:')\n",
    "    with tf.device('GPU:0'):# Or GPU:1 for the 2nd GPU, GPU:2 for the third etc\n",
    "        x = tf.random.uniform([1000,1000])\n",
    "        assert x.device.endswith('GPU:0')\n",
    "        time_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS\n",
    "###################\n",
    "# This section uses the (tf.data.Dataset) API to build a pipeliine \n",
    "# for feeding data to your model\n",
    "# The (tf.data.Dataset) API is used to build performant, complex\n",
    "# input pipelines from simple, re-usable pieces that will feed\n",
    "# your model's training or evaluation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 /tmp/tmpj0mnoqwa\n",
      "ds_file read <DatasetV1Adapter shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "# Create a source Dataset\n",
    "############################\n",
    "# create a source dataset using one of the factory functions\n",
    "# like:\n",
    "# (Dataset.from_tensors)\n",
    "# (Dataset.from_tensor_slices)\n",
    "## or using objects that read from files like:\n",
    "# (TextLineDataset) or (TFRecordDataset)\n",
    "\n",
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6])\n",
    "# print(ds_tensors)\n",
    "# Create a csv file\n",
    "import tempfile\n",
    "_,filename = tempfile.mkstemp()\n",
    "print(_,filename)\n",
    "with open(filename,'w') as f:\n",
    "    f.write('''line 1\n",
    "    line 2\n",
    "    line 3\n",
    "    ''')\n",
    "    f.close()\n",
    "ds_file = tf.data.TextLineDataset(filename)\n",
    "print('ds_file read',ds_file.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (?, ?), types: tf.int32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying trainsformations\n",
    "############################\n",
    "# Use the transformation functions like (map),(batch) and \n",
    "# (shuffle) to apply transformations to dataset records.\n",
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "ds_file = ds_file.batch(2)\n",
    "# ds_file\n",
    "# ds_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of ds_tensors:\n",
      "tf.Tensor(\n",
      "[[  81  256]\n",
      " [1296  625]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor([[ 1 16]], shape=(1, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Iterate\n",
    "##############\n",
    "# (tf.data.Dataset) object supports iteration to loop over records\n",
    "\n",
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in ds_file\n",
      "tf.Tensor(\n",
      "[[b'line 1' b'    line 2']\n",
      " [b'    line 3' b'    ']], shape=(2, 2), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('Elements in ds_file')\n",
    "for x in ds_file:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
