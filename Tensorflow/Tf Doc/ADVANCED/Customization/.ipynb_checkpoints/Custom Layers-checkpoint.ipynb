{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers: common sets of useful operations\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the (tf.keras) layers package, layers are objects.\n",
    "# To construct a layer, simply construct the object.\n",
    "# Most layers take as a first argument the number of \n",
    "# outputs dimensions / channels.\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "# The number of input dimensions is often unnecessary, as it\n",
    "# can be inferred the first time the layer is used, but it can \n",
    "# be provided if you want to specify it manually, which is \n",
    "# useful in some complex models.\n",
    "layers = tf.keras.layers.Dense(10, input_shape=(None,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(10, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use a layer, simply call it.\n",
    "layer(tf.zeros([10,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
       " array([[-0.09680159,  0.13405772, -0.23887354,  0.0005852 , -0.17341083,\n",
       "          0.2388549 , -0.14115886,  0.03481625,  0.11024748, -0.12936339,\n",
       "          0.20863976,  0.05590476, -0.21312864, -0.18221481, -0.19740605,\n",
       "         -0.20674491, -0.23889595,  0.01485698,  0.19680871,  0.12438978,\n",
       "         -0.02485622, -0.03637654, -0.10542737, -0.11718638, -0.14606482,\n",
       "          0.19222237,  0.05290551,  0.1994885 , -0.15359569, -0.12860936,\n",
       "         -0.04444189, -0.00857937,  0.20345198,  0.21678604,  0.13439785,\n",
       "         -0.16697177,  0.0136167 , -0.11108653, -0.09517235,  0.00290789,\n",
       "         -0.08293977,  0.05326702, -0.08537446,  0.18072285,  0.0544825 ,\n",
       "          0.0494227 ,  0.07514314, -0.1151906 , -0.04932432,  0.10270612,\n",
       "         -0.18567047,  0.01916189,  0.04062064,  0.23193477,  0.19225092,\n",
       "          0.11623819,  0.20063446, -0.2228774 ,  0.00431949, -0.10611476,\n",
       "         -0.22147223, -0.09024109,  0.0930994 ,  0.13770913, -0.11256778,\n",
       "         -0.07602437,  0.14823641,  0.00717638, -0.22803229, -0.16472289,\n",
       "         -0.15597242, -0.02103125,  0.14188124,  0.04515557, -0.2064237 ,\n",
       "          0.16133626, -0.2334195 , -0.22868738, -0.17155376, -0.0711305 ,\n",
       "          0.04520611, -0.04523747, -0.11705717,  0.04443602,  0.15689935,\n",
       "          0.19320054,  0.11669226, -0.21699117, -0.19857281,  0.06282474,\n",
       "          0.01818793, -0.15196016,  0.16819625, -0.07480085, -0.18286613,\n",
       "          0.13038133,  0.11784704,  0.22063069,  0.22463329, -0.14968273],\n",
       "        [ 0.03134345,  0.00414127,  0.10701074,  0.06064858, -0.16793221,\n",
       "         -0.06527385, -0.04928915,  0.14927997,  0.13054149, -0.2382293 ,\n",
       "          0.19892935,  0.10248516,  0.1713246 , -0.17200926,  0.09122364,\n",
       "         -0.19527799,  0.18363293, -0.04874361, -0.038212  ,  0.03199692,\n",
       "         -0.00584446, -0.03006287, -0.15694112,  0.08607952, -0.1595807 ,\n",
       "          0.13924299,  0.17606892,  0.08824496, -0.13717979,  0.0658031 ,\n",
       "          0.06105842,  0.00927463, -0.08823055, -0.11399153, -0.14578709,\n",
       "         -0.1214278 , -0.17360699, -0.07616839, -0.22724248,  0.13547309,\n",
       "          0.03667821, -0.15165144,  0.13966964,  0.20951448, -0.08503723,\n",
       "          0.23313053,  0.06502245, -0.03604479,  0.11620672,  0.07306112,\n",
       "         -0.22332667,  0.11015464, -0.17648782, -0.18839473, -0.11182916,\n",
       "          0.19895478,  0.15059318, -0.08043665, -0.18195726, -0.2361714 ,\n",
       "          0.01947619, -0.18499681,  0.06806256,  0.20166205, -0.17634323,\n",
       "         -0.01108393, -0.01465124,  0.01013295, -0.03019144, -0.14001724,\n",
       "         -0.16788349, -0.0207537 ,  0.05547015, -0.03332081,  0.194463  ,\n",
       "          0.16104884,  0.11122082, -0.07981634,  0.12327294,  0.2328751 ,\n",
       "         -0.18344745,  0.13325559, -0.05361617, -0.17644177, -0.11327547,\n",
       "         -0.11026424, -0.16524836, -0.22614737,  0.00480211, -0.1175627 ,\n",
       "          0.18309285,  0.00193201, -0.10327674, -0.15777066,  0.12734087,\n",
       "         -0.05779853, -0.01988956, -0.01602516,  0.12794863, -0.22100501],\n",
       "        [-0.07899866, -0.11921874,  0.22389843,  0.03923292, -0.15899816,\n",
       "         -0.16430473, -0.05725101,  0.16652317,  0.13824238,  0.15626855,\n",
       "          0.1827118 , -0.20212023, -0.23300771, -0.05416912, -0.02364956,\n",
       "          0.03686242, -0.07015638, -0.06093538,  0.05887695, -0.18292381,\n",
       "          0.13881202,  0.14285286,  0.00278285, -0.05569589,  0.04873262,\n",
       "         -0.15263444,  0.13602631, -0.05572674, -0.12810406,  0.22626944,\n",
       "          0.10431738, -0.1254478 ,  0.09170319,  0.13447355,  0.190897  ,\n",
       "         -0.02845372,  0.21543838,  0.14343016, -0.00599281,  0.02563314,\n",
       "          0.17440633,  0.15822186, -0.09473589, -0.08369157, -0.05214609,\n",
       "         -0.07098739, -0.10234548,  0.14446314,  0.15330629,  0.08602138,\n",
       "          0.09958632, -0.01056182, -0.1916248 ,  0.09601562,  0.12441404,\n",
       "          0.107217  , -0.11496662, -0.20185675,  0.08922558, -0.22884974,\n",
       "          0.12023015,  0.09771855, -0.16034281, -0.05520649, -0.06360829,\n",
       "         -0.23388821, -0.04772726, -0.00260286,  0.20894252, -0.11921168,\n",
       "         -0.23080078, -0.06811933, -0.08098002, -0.20988284,  0.20299895,\n",
       "         -0.11271186,  0.21507506, -0.05284442,  0.12301044,  0.07147683,\n",
       "          0.15954514, -0.17348868, -0.01683025, -0.13900995,  0.11386006,\n",
       "         -0.02341333,  0.18815537, -0.18865871, -0.0121672 , -0.01356769,\n",
       "          0.06162675,  0.02330013,  0.2377962 , -0.06818551,  0.04816024,\n",
       "          0.09872471,  0.03586166,  0.1636651 ,  0.09016632, -0.07286416],\n",
       "        [-0.14450088, -0.2203933 ,  0.03521805,  0.0549493 ,  0.23480771,\n",
       "          0.15111752,  0.23832248, -0.20397244,  0.04866119, -0.13993892,\n",
       "          0.19716145, -0.19482267, -0.21147795, -0.2190282 ,  0.13490014,\n",
       "         -0.05906178, -0.02865434,  0.0042523 , -0.17523403,  0.18622114,\n",
       "          0.09729488,  0.20741089, -0.16096015, -0.21679585,  0.14356755,\n",
       "          0.02848278, -0.0620057 , -0.19920139,  0.08475296,  0.14213242,\n",
       "          0.12186806,  0.23337577, -0.02048384, -0.21858737, -0.20823237,\n",
       "         -0.07747158, -0.02420786, -0.07302529,  0.10464592, -0.12280965,\n",
       "         -0.22756381, -0.17738803,  0.1612979 , -0.03017172,  0.12019767,\n",
       "          0.15719469,  0.11691327, -0.22262828,  0.1520337 ,  0.19621395,\n",
       "          0.13610394,  0.18912931, -0.15432754,  0.09065987, -0.2049127 ,\n",
       "          0.18542813,  0.02782656, -0.14667013, -0.11685331,  0.1340393 ,\n",
       "          0.11620001,  0.01188861,  0.18912773, -0.22904888, -0.11141226,\n",
       "         -0.2011689 , -0.0501478 ,  0.11972056,  0.08336689, -0.02330863,\n",
       "          0.16050382,  0.1281573 ,  0.05918084, -0.00159922, -0.06600489,\n",
       "         -0.08805534,  0.01209106,  0.10817136, -0.14493829,  0.15916921,\n",
       "          0.19925125,  0.09777953,  0.16252251,  0.19929008, -0.07102752,\n",
       "         -0.23257503,  0.00346284,  0.10297997, -0.08177707,  0.18887426,\n",
       "          0.0759614 , -0.06190591, -0.14049068,  0.02288015,  0.21875577,\n",
       "          0.06208093,  0.16632776, -0.236757  ,  0.14966302, -0.23884745],\n",
       "        [-0.02341732,  0.05975004, -0.07500181, -0.03818123,  0.03657795,\n",
       "          0.00726968, -0.00185096, -0.00605692, -0.12384612,  0.00396836,\n",
       "         -0.06977105,  0.10130359, -0.17643915,  0.09009303,  0.2126164 ,\n",
       "         -0.08197266, -0.18035473, -0.08525836,  0.02674894, -0.22393793,\n",
       "         -0.10933498,  0.10599206,  0.07312559, -0.09185137, -0.23513271,\n",
       "          0.13604586,  0.21269931,  0.05056356, -0.11932036,  0.15471913,\n",
       "          0.03218712,  0.03992112,  0.09568073,  0.12029551, -0.12137912,\n",
       "          0.11466976,  0.16267325,  0.02829374,  0.05237986,  0.2383549 ,\n",
       "         -0.17267609, -0.10365734,  0.1061257 ,  0.15130116, -0.13149793,\n",
       "          0.01232032,  0.00976375,  0.11804076,  0.12252714, -0.14766085,\n",
       "          0.18239172,  0.11503626,  0.09859647, -0.1122818 ,  0.0247594 ,\n",
       "         -0.06503898,  0.06685801, -0.08011007, -0.01535982, -0.01375644,\n",
       "         -0.18536425,  0.1389016 ,  0.12453659, -0.12252577, -0.04462889,\n",
       "         -0.00428598,  0.0891331 ,  0.15269138, -0.06196746, -0.18234818,\n",
       "         -0.12210897,  0.06287073,  0.17059077, -0.09003751,  0.13282497,\n",
       "         -0.03640042, -0.20729227,  0.20314206,  0.04940803, -0.2283294 ,\n",
       "          0.12085901,  0.06157403, -0.06034744, -0.06706001, -0.00584781,\n",
       "          0.19780426, -0.00999378,  0.08253945, -0.20520958, -0.09836692,\n",
       "          0.06191371, -0.23792057,  0.04784261, -0.00543655,  0.02527671,\n",
       "         -0.09464647, -0.11064456,  0.23505549,  0.23219194,  0.1872261 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layers have many useful methos. For example, you can inspect\n",
    "# all variables in a layer using `layer.variables` and \n",
    "# trainable variables using `layer.trainable_variables`.\n",
    "# In this case a fully-connected layer will have variables\n",
    "# for weights and biases\n",
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'dense/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
       " array([[-0.09680159,  0.13405772, -0.23887354,  0.0005852 , -0.17341083,\n",
       "          0.2388549 , -0.14115886,  0.03481625,  0.11024748, -0.12936339,\n",
       "          0.20863976,  0.05590476, -0.21312864, -0.18221481, -0.19740605,\n",
       "         -0.20674491, -0.23889595,  0.01485698,  0.19680871,  0.12438978,\n",
       "         -0.02485622, -0.03637654, -0.10542737, -0.11718638, -0.14606482,\n",
       "          0.19222237,  0.05290551,  0.1994885 , -0.15359569, -0.12860936,\n",
       "         -0.04444189, -0.00857937,  0.20345198,  0.21678604,  0.13439785,\n",
       "         -0.16697177,  0.0136167 , -0.11108653, -0.09517235,  0.00290789,\n",
       "         -0.08293977,  0.05326702, -0.08537446,  0.18072285,  0.0544825 ,\n",
       "          0.0494227 ,  0.07514314, -0.1151906 , -0.04932432,  0.10270612,\n",
       "         -0.18567047,  0.01916189,  0.04062064,  0.23193477,  0.19225092,\n",
       "          0.11623819,  0.20063446, -0.2228774 ,  0.00431949, -0.10611476,\n",
       "         -0.22147223, -0.09024109,  0.0930994 ,  0.13770913, -0.11256778,\n",
       "         -0.07602437,  0.14823641,  0.00717638, -0.22803229, -0.16472289,\n",
       "         -0.15597242, -0.02103125,  0.14188124,  0.04515557, -0.2064237 ,\n",
       "          0.16133626, -0.2334195 , -0.22868738, -0.17155376, -0.0711305 ,\n",
       "          0.04520611, -0.04523747, -0.11705717,  0.04443602,  0.15689935,\n",
       "          0.19320054,  0.11669226, -0.21699117, -0.19857281,  0.06282474,\n",
       "          0.01818793, -0.15196016,  0.16819625, -0.07480085, -0.18286613,\n",
       "          0.13038133,  0.11784704,  0.22063069,  0.22463329, -0.14968273],\n",
       "        [ 0.03134345,  0.00414127,  0.10701074,  0.06064858, -0.16793221,\n",
       "         -0.06527385, -0.04928915,  0.14927997,  0.13054149, -0.2382293 ,\n",
       "          0.19892935,  0.10248516,  0.1713246 , -0.17200926,  0.09122364,\n",
       "         -0.19527799,  0.18363293, -0.04874361, -0.038212  ,  0.03199692,\n",
       "         -0.00584446, -0.03006287, -0.15694112,  0.08607952, -0.1595807 ,\n",
       "          0.13924299,  0.17606892,  0.08824496, -0.13717979,  0.0658031 ,\n",
       "          0.06105842,  0.00927463, -0.08823055, -0.11399153, -0.14578709,\n",
       "         -0.1214278 , -0.17360699, -0.07616839, -0.22724248,  0.13547309,\n",
       "          0.03667821, -0.15165144,  0.13966964,  0.20951448, -0.08503723,\n",
       "          0.23313053,  0.06502245, -0.03604479,  0.11620672,  0.07306112,\n",
       "         -0.22332667,  0.11015464, -0.17648782, -0.18839473, -0.11182916,\n",
       "          0.19895478,  0.15059318, -0.08043665, -0.18195726, -0.2361714 ,\n",
       "          0.01947619, -0.18499681,  0.06806256,  0.20166205, -0.17634323,\n",
       "         -0.01108393, -0.01465124,  0.01013295, -0.03019144, -0.14001724,\n",
       "         -0.16788349, -0.0207537 ,  0.05547015, -0.03332081,  0.194463  ,\n",
       "          0.16104884,  0.11122082, -0.07981634,  0.12327294,  0.2328751 ,\n",
       "         -0.18344745,  0.13325559, -0.05361617, -0.17644177, -0.11327547,\n",
       "         -0.11026424, -0.16524836, -0.22614737,  0.00480211, -0.1175627 ,\n",
       "          0.18309285,  0.00193201, -0.10327674, -0.15777066,  0.12734087,\n",
       "         -0.05779853, -0.01988956, -0.01602516,  0.12794863, -0.22100501],\n",
       "        [-0.07899866, -0.11921874,  0.22389843,  0.03923292, -0.15899816,\n",
       "         -0.16430473, -0.05725101,  0.16652317,  0.13824238,  0.15626855,\n",
       "          0.1827118 , -0.20212023, -0.23300771, -0.05416912, -0.02364956,\n",
       "          0.03686242, -0.07015638, -0.06093538,  0.05887695, -0.18292381,\n",
       "          0.13881202,  0.14285286,  0.00278285, -0.05569589,  0.04873262,\n",
       "         -0.15263444,  0.13602631, -0.05572674, -0.12810406,  0.22626944,\n",
       "          0.10431738, -0.1254478 ,  0.09170319,  0.13447355,  0.190897  ,\n",
       "         -0.02845372,  0.21543838,  0.14343016, -0.00599281,  0.02563314,\n",
       "          0.17440633,  0.15822186, -0.09473589, -0.08369157, -0.05214609,\n",
       "         -0.07098739, -0.10234548,  0.14446314,  0.15330629,  0.08602138,\n",
       "          0.09958632, -0.01056182, -0.1916248 ,  0.09601562,  0.12441404,\n",
       "          0.107217  , -0.11496662, -0.20185675,  0.08922558, -0.22884974,\n",
       "          0.12023015,  0.09771855, -0.16034281, -0.05520649, -0.06360829,\n",
       "         -0.23388821, -0.04772726, -0.00260286,  0.20894252, -0.11921168,\n",
       "         -0.23080078, -0.06811933, -0.08098002, -0.20988284,  0.20299895,\n",
       "         -0.11271186,  0.21507506, -0.05284442,  0.12301044,  0.07147683,\n",
       "          0.15954514, -0.17348868, -0.01683025, -0.13900995,  0.11386006,\n",
       "         -0.02341333,  0.18815537, -0.18865871, -0.0121672 , -0.01356769,\n",
       "          0.06162675,  0.02330013,  0.2377962 , -0.06818551,  0.04816024,\n",
       "          0.09872471,  0.03586166,  0.1636651 ,  0.09016632, -0.07286416],\n",
       "        [-0.14450088, -0.2203933 ,  0.03521805,  0.0549493 ,  0.23480771,\n",
       "          0.15111752,  0.23832248, -0.20397244,  0.04866119, -0.13993892,\n",
       "          0.19716145, -0.19482267, -0.21147795, -0.2190282 ,  0.13490014,\n",
       "         -0.05906178, -0.02865434,  0.0042523 , -0.17523403,  0.18622114,\n",
       "          0.09729488,  0.20741089, -0.16096015, -0.21679585,  0.14356755,\n",
       "          0.02848278, -0.0620057 , -0.19920139,  0.08475296,  0.14213242,\n",
       "          0.12186806,  0.23337577, -0.02048384, -0.21858737, -0.20823237,\n",
       "         -0.07747158, -0.02420786, -0.07302529,  0.10464592, -0.12280965,\n",
       "         -0.22756381, -0.17738803,  0.1612979 , -0.03017172,  0.12019767,\n",
       "          0.15719469,  0.11691327, -0.22262828,  0.1520337 ,  0.19621395,\n",
       "          0.13610394,  0.18912931, -0.15432754,  0.09065987, -0.2049127 ,\n",
       "          0.18542813,  0.02782656, -0.14667013, -0.11685331,  0.1340393 ,\n",
       "          0.11620001,  0.01188861,  0.18912773, -0.22904888, -0.11141226,\n",
       "         -0.2011689 , -0.0501478 ,  0.11972056,  0.08336689, -0.02330863,\n",
       "          0.16050382,  0.1281573 ,  0.05918084, -0.00159922, -0.06600489,\n",
       "         -0.08805534,  0.01209106,  0.10817136, -0.14493829,  0.15916921,\n",
       "          0.19925125,  0.09777953,  0.16252251,  0.19929008, -0.07102752,\n",
       "         -0.23257503,  0.00346284,  0.10297997, -0.08177707,  0.18887426,\n",
       "          0.0759614 , -0.06190591, -0.14049068,  0.02288015,  0.21875577,\n",
       "          0.06208093,  0.16632776, -0.236757  ,  0.14966302, -0.23884745],\n",
       "        [-0.02341732,  0.05975004, -0.07500181, -0.03818123,  0.03657795,\n",
       "          0.00726968, -0.00185096, -0.00605692, -0.12384612,  0.00396836,\n",
       "         -0.06977105,  0.10130359, -0.17643915,  0.09009303,  0.2126164 ,\n",
       "         -0.08197266, -0.18035473, -0.08525836,  0.02674894, -0.22393793,\n",
       "         -0.10933498,  0.10599206,  0.07312559, -0.09185137, -0.23513271,\n",
       "          0.13604586,  0.21269931,  0.05056356, -0.11932036,  0.15471913,\n",
       "          0.03218712,  0.03992112,  0.09568073,  0.12029551, -0.12137912,\n",
       "          0.11466976,  0.16267325,  0.02829374,  0.05237986,  0.2383549 ,\n",
       "         -0.17267609, -0.10365734,  0.1061257 ,  0.15130116, -0.13149793,\n",
       "          0.01232032,  0.00976375,  0.11804076,  0.12252714, -0.14766085,\n",
       "          0.18239172,  0.11503626,  0.09859647, -0.1122818 ,  0.0247594 ,\n",
       "         -0.06503898,  0.06685801, -0.08011007, -0.01535982, -0.01375644,\n",
       "         -0.18536425,  0.1389016 ,  0.12453659, -0.12252577, -0.04462889,\n",
       "         -0.00428598,  0.0891331 ,  0.15269138, -0.06196746, -0.18234818,\n",
       "         -0.12210897,  0.06287073,  0.17059077, -0.09003751,  0.13282497,\n",
       "         -0.03640042, -0.20729227,  0.20314206,  0.04940803, -0.2283294 ,\n",
       "          0.12085901,  0.06157403, -0.06034744, -0.06706001, -0.00584781,\n",
       "          0.19780426, -0.00999378,  0.08253945, -0.20520958, -0.09836692,\n",
       "          0.06191371, -0.23792057,  0.04784261, -0.00543655,  0.02527671,\n",
       "         -0.09464647, -0.11064456,  0.23505549,  0.23219194,  0.1872261 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variables are also accessible through nice accessors\n",
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=76, shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing custom layers\n",
    "##############################\n",
    "# The best way is \n",
    "## Extend the tf.keras.Layer class\n",
    "##and implementing: *(__init__), where you can do all input-independent\n",
    "# initialization*\n",
    "# *(build), where you know the shapes of the input tensors \n",
    "# and can do the rest of the initialization*\n",
    "# *(call), where you do the forward computation*\n",
    "\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_outputs):\n",
    "        super(MyDenseLayer,self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        self.kernel = self.add_variable('kernel',\n",
    "                                       shape=[int(input_shape[-1]),\n",
    "                                             self.num_outputs])\n",
    "        \n",
    "    def call(self,input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "    \n",
    "layer = MyDenseLayer(10)\n",
    "\n",
    "_ = layer(tf.zeros([10,5])) # Calling the layer `.builds it`.\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_dense_layer_2/kernel:0']\n"
     ]
    }
   ],
   "source": [
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models: Composing Layers\n",
    "#############################\n",
    "# Many interesting layer-like things in machine learning\n",
    "# models are implemented by composing existing layers.\n",
    "# Typically you can inherit from (keras.Model) when you need \n",
    "# the model methods like:\n",
    "## (Model.fit), (Model.evaluate) and (Model.save) etc\n",
    "#######\n",
    "# One othe feature provided by (keras.Model) instead of \n",
    "# (keras.layers.Layer) is that in addition to tracking \n",
    "# variables, a (keras.Model) also tracks its internal layers,\n",
    "# making them easier to inspect.\n",
    "###################\n",
    "'eg. Here is a ResNet block'\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self,kernel_size, filters):\n",
    "        super(ResnetIdentityBlock,self).__init__(name='')\n",
    "        filters1,filters2,filters3 = filters\n",
    "        \n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1,1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size,padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "    \n",
    "    \n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "    \n",
    "block = ResnetIdentityBlock(1, [1,2,3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7efd709b59d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7efd93eba810>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7efd7108b350>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7efd7108b990>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7efd71814b50>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7efd71814dd0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4e4d1bcaca03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \"\"\"\n\u001b[1;32m   1503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1505\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=499, shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (tf.keras.Sequential)\n",
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 2)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, None, 2)     8         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 3)     9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, None, 3)     12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_seq.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
