{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guide uses machine learning to categorize Iris flowers \n",
    "# by species\n",
    "########################\n",
    "# 1. Build a model\n",
    "# 2. Train this model on example data\n",
    "# 3. Use the model to make predictions about unknown data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "# configure Imports\n",
    "####################\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.14.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: /home/george/.keras/datasets/iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "# THE IRIS CLASSIFICATION PROBLEM\n",
    "#################################\n",
    "# Import and parse the traininig dataset\n",
    "# Download the dataset\n",
    "training_dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv'\n",
    "train_dataset_fp = tf.keras.utils.get_file(\n",
    "    fname=os.path.basename(training_dataset_url),\n",
    "    origin=training_dataset_url\n",
    ")\n",
    "print('Local copy of the dataset file: {}'.format(\n",
    "    train_dataset_fp\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120,4,setosa,versicolor,virginica\r\n",
      "6.4,2.8,5.6,2.2,2\r\n",
      "5.0,2.3,3.3,1.0,1\r\n",
      "4.9,2.5,4.5,1.7,2\r\n",
      "4.9,3.1,1.5,0.1,0\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect the data\n",
    "###################\n",
    "!head -n5 {train_dataset_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    }
   ],
   "source": [
    "# column order in CSV file\n",
    "column_names = ['sepal_length','sepal_width',\n",
    "                'petal_length','petal_width',\n",
    "                'species']\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print('Features: {}'.format(feature_names))\n",
    "print('Label: {}'.format(label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 -> Iris Setosa\n",
    "# 1 -> Iris Versicolor\n",
    "# 2 -> Iris Virginica\n",
    "class_names = ['Iris setosa','Iris versicolor','Iris virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a (tf.data.Dataset)\n",
    "################################\n",
    "# since the dataset is a CSV-formatted text file, use the \n",
    "# (make_csv_dataset) function to parse the data into a suitable\n",
    "# format.\n",
    "# Since this function generates data for training models, the\n",
    "# default behaviour is to shuffle the data (shuffle=True),\n",
    "# (shuffle_buffer_size=10000), and repeat the dataset forever\n",
    "# (num_epochs=None).\n",
    "# We also set the (batch_size) parameter\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('sepal_length', <tf.Tensor: id=275, shape=(32,), dtype=float32, numpy=\n",
      "array([6.7, 6.4, 6.8, 6.6, 5.1, 6.6, 7.2, 4.9, 6. , 5.1, 6.7, 6.3, 6.8,\n",
      "       5. , 7.7, 5.5, 7.3, 4.4, 6.4, 4.9, 4.9, 4.6, 5.2, 6.3, 5. , 5.7,\n",
      "       4.6, 6.5, 6.3, 5.8, 4.8, 6.9], dtype=float32)>), ('sepal_width', <tf.Tensor: id=276, shape=(32,), dtype=float32, numpy=\n",
      "array([3.3, 3.2, 2.8, 3. , 3.7, 2.9, 3. , 3.1, 2.9, 2.5, 3.1, 3.4, 3.2,\n",
      "       3.5, 3. , 2.4, 2.9, 2.9, 3.1, 2.5, 2.4, 3.2, 2.7, 3.3, 3.4, 3.8,\n",
      "       3.1, 3. , 2.7, 4. , 3. , 3.2], dtype=float32)>), ('petal_length', <tf.Tensor: id=273, shape=(32,), dtype=float32, numpy=\n",
      "array([5.7, 4.5, 4.8, 4.4, 1.5, 4.6, 5.8, 1.5, 4.5, 3. , 4.4, 5.6, 5.9,\n",
      "       1.3, 6.1, 3.8, 6.3, 1.4, 5.5, 4.5, 3.3, 1.4, 3.9, 4.7, 1.5, 1.7,\n",
      "       1.5, 5.5, 4.9, 1.2, 1.4, 5.7], dtype=float32)>), ('petal_width', <tf.Tensor: id=274, shape=(32,), dtype=float32, numpy=\n",
      "array([2.1, 1.5, 1.4, 1.4, 0.4, 1.3, 1.6, 0.1, 1.5, 1.1, 1.4, 2.4, 2.3,\n",
      "       0.3, 2.3, 1.1, 1.8, 0.2, 1.8, 1.7, 1. , 0.2, 1.4, 1.6, 0.2, 0.3,\n",
      "       0.2, 1.8, 1.8, 0.2, 0.1, 2.3], dtype=float32)>)])\n"
     ]
    }
   ],
   "source": [
    "# The (make_csv_dataset) function returns a (tf.data.Dataset)\n",
    "# of (features, label) pairs, where (features) is dictionary:-\n",
    "# {'feature_name':value}\n",
    "# These Dataset objects are iterable.\n",
    "# Let's look at a batch of features\n",
    "\n",
    "features, labels = next(iter(train_dataset))\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# confirm the batch size\n",
    "for f in features:\n",
    "    print(len(features[f].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See some clusters by plotting a few features from the batch\n",
    "###############################################################\n",
    "plt.scatter(\n",
    "    features['petal_length'],\n",
    "    features['sepal_length'],\n",
    "    c=labels,\n",
    "    cmap='viridis'\n",
    ")\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Sepal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify the model building step, create a function to \n",
    "# repackage the features dictionary into a single array\n",
    "# with shape (batch_size, num_features).\n",
    "# This function uses the (tf.stack) method which takes values\n",
    "# from a list of tensors and creates a combined tensor at the \n",
    "# specified dimension\n",
    "\n",
    "def pack_features_vector(features, labels):\n",
    "    '''Pack the features into a single array'''\n",
    "    features = tf.stack(list(features.values()), axis=1)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the (tf.data.Dataset.map) method to pack the (features) \n",
    "# of each (features,label) pair into the training dataset.\n",
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6.7 3.3 5.7 2.1]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.1 3.7 1.5 0.4]], shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# The feature element of the (Dataset) are now arrays with\n",
    "# shape (batch_size, num_features). \n",
    "features, labels = next(iter(train_dataset))\n",
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the type of model\n",
    "##########################\n",
    "# A model is a relationship between features and the label.\n",
    "######\n",
    "# Create a model using Keras\n",
    "############################\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=481, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[3.5379252 , 2.5882993 , 1.1494532 ],\n",
       "       [2.6911721 , 1.8851736 , 0.96337473],\n",
       "       [2.9838514 , 2.1036763 , 1.052392  ],\n",
       "       [2.6502433 , 1.8339763 , 0.97241503],\n",
       "       [0.13276246, 0.4292511 , 0.1985964 ]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the model\n",
    "####################\n",
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=548, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.6762901 , 0.26164696, 0.062063  ],\n",
       "       [0.6156434 , 0.27497202, 0.10938465],\n",
       "       [0.6411708 , 0.26590014, 0.09292907],\n",
       "       [0.61392707, 0.27140418, 0.11466879],\n",
       "       [0.2929822 , 0.39409834, 0.31291944]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COnver the logitsto a probability for each class,\n",
    "# use (softmax) function\n",
    "tf.nn.softmax(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm softmax\n",
    "tf.reduce_sum(tf.nn.softmax(predictions[:5][3])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0]\n",
      "         Labels: [2 1 1 1 0 1 2 0 1 1 1 2 2 0 2 1 2 0 2 2 1 0 1 1 0 0 0 2 2 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Taking the (tf.argmax) across classes gives us the predicted\n",
    "# class index.\n",
    "# But the model has'nt been trained yet, so these aren't \n",
    "# predictions\n",
    "print('Prediction: {}'.format(\n",
    "    tf.argmax(predictions, axis=1)\n",
    "))\n",
    "print('         Labels: {}'.format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "##################\n",
    "# Define the loss and gradient function\n",
    "####\n",
    "# Or model will calculate its loss using the\n",
    "# (tf.keras.losses.SparseCategoricalCrossentropy) function\n",
    "# which takes the model's class probability predictions and the\n",
    "# desired label, and returns the average loss across the \n",
    "# examples\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss test: 1.7599759101867676\n"
     ]
    }
   ],
   "source": [
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "l = loss(model, features, labels)\n",
    "print('loss test: {}'.format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the (tf.GradientTape) context to calculate the gradients\n",
    "# used to optimize your model.\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer\n",
    "######################\n",
    "# An optimizer applies the computed gradients to the model's \n",
    "# variables to minimize the loss function.\n",
    "## #\n",
    "# This model uses the (tf.keras.optimizers.SGD) that implements\n",
    "# the stochastic gradient descent (SGD) algorithm.\n",
    "# The learning_rate sets the step size to take for each \n",
    "# iteration down the hill.\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 1.7599759101867676\n",
      "Step: 1,          Loss: 1.6822283267974854\n"
     ]
    }
   ],
   "source": [
    "# We'll use this to calculate a single optimization step\n",
    "loss_value, grads = grad(model,features, labels)\n",
    "\n",
    "print('Step: {}, Initial Loss: {}'.format(\n",
    "    optimizer.iterations.numpy(),\n",
    "    loss_value.numpy()\n",
    "))\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "print('Step: {},          Loss: {}'.format(\n",
    "    optimizer.iterations.numpy(),\n",
    "    loss(model, features, labels).numpy()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 1.682, Accuracy: 0.000%\n",
      "Epoch 050: Loss: 1.682, Accuracy: 35.000%\n",
      "Epoch 100: Loss: 1.682, Accuracy: 35.000%\n",
      "Epoch 150: Loss: 1.682, Accuracy: 35.000%\n",
      "Epoch 200: Loss: 1.682, Accuracy: 35.000%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "################\n",
    "# 1. Iterate each epoch. (epoch is one pass through the dataset)\n",
    "# 2. Within an epoch, iterate over each example in the training\n",
    "# (Dataset) grabbing its features (x) and label (y)\n",
    "# 3. Using the example's features, make a prediction and \n",
    "# compare it with the label.\n",
    "# Measure the inaccuracy of the prediction and use that to \n",
    "# calculate the model's loss and gradients\n",
    "# 4. Use an (optimizer) to update the model's variables\n",
    "# 5. Keep track of some stats for visualization\n",
    "# 6. Repeat for each epoch\n",
    "\n",
    "####################\n",
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in train_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(y, model(x))\n",
    "\n",
    "  # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  if epoch % 50 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss function over time\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12,8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel('Loss',fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's effectiveness\n",
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the test dataset\n",
    "#####################\n",
    "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
    "                                  origin=test_url)\n",
    "\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    test_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name='species',\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_dataset = test_dataset.map(pack_features_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.000%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "#####\n",
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "for (x,y) in test_dataset:\n",
    "    logits = model(x)\n",
    "    prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "    test_accuracy(prediction, y)\n",
    "                  \n",
    "                  \n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1178, shape=(30, 2), dtype=int32, numpy=\n",
       "array([[1, 0],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see on the batch, eg. the model is usually correct\n",
    "tf.stack([y, prediction], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0 prediction: Iris versicolor (35.6%)\n",
      "Example 1 prediction: Iris setosa (54.7%)\n",
      "Example 2 prediction: Iris setosa (61.6%)\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions\n",
    "predict_dataset = tf.convert_to_tensor([\n",
    "    [5.1, 3.3, 1.7, 0.5,],\n",
    "    [5.9, 3.0, 4.2, 1.5,],\n",
    "    [6.9, 3.1, 5.4, 2.1]\n",
    "])\n",
    "\n",
    "predictions = model(predict_dataset)\n",
    "for i, logits in enumerate(predictions):\n",
    "  class_idx = tf.argmax(logits).numpy()\n",
    "  p = tf.nn.softmax(logits)[class_idx]\n",
    "  name = class_names[class_idx]\n",
    "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
