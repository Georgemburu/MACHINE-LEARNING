{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spanish to English ML Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Georgemburu/MACHINE-LEARNING/blob/master/Spanish_to_English_ML_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0FhAms6rUJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgWa3nHVteEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8656d63b-5c82-40c9-a659-4a67caddf377"
      },
      "source": [
        "from __future__ import print_function, absolute_import,division,unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68OXm_rbuIs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD DATASET\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip',\n",
        "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True\n",
        ")\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+'/spa-eng/spa.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKC1bn5tuijF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d6de033-ec3e-4e9e-a1ac-82bb68a60a65"
      },
      "source": [
        "path_to_file"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3II2679vukUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "d1444b41-8ec1-4e1c-cf3d-77714d46024b"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(path_to_file, delimiter='\\t')\n",
        "data"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Go.</th>\n",
              "      <th>Ve.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>¡Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118958</th>\n",
              "      <td>There are four main causes of alcohol-related ...</td>\n",
              "      <td>Hay cuatro causas principales de muertes relac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118959</th>\n",
              "      <td>There are mothers and fathers who will lie awa...</td>\n",
              "      <td>Hay madres y padres que se quedan despiertos d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118960</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Una huella de carbono es la cantidad de contam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118961</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Como suele haber varias páginas web sobre cual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118962</th>\n",
              "      <td>If you want to sound like a native speaker, yo...</td>\n",
              "      <td>Si quieres sonar como un hablante nativo, debe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>118963 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      Go.                                                Ve.\n",
              "0                                                     Go.                                              Vete.\n",
              "1                                                     Go.                                              Vaya.\n",
              "2                                                     Go.                                            Váyase.\n",
              "3                                                     Hi.                                              Hola.\n",
              "4                                                    Run!                                            ¡Corre!\n",
              "...                                                   ...                                                ...\n",
              "118958  There are four main causes of alcohol-related ...  Hay cuatro causas principales de muertes relac...\n",
              "118959  There are mothers and fathers who will lie awa...  Hay madres y padres que se quedan despiertos d...\n",
              "118960  A carbon footprint is the amount of carbon dio...  Una huella de carbono es la cantidad de contam...\n",
              "118961  Since there are usually multiple websites on a...  Como suele haber varias páginas web sobre cual...\n",
              "118962  If you want to sound like a native speaker, yo...  Si quieres sonar como un hablante nativo, debe...\n",
              "\n",
              "[118963 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEKcAPqAukdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s) \n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.rstrip().strip()\n",
        "\n",
        "  # Add a start and end token\n",
        "  w = '<start> '+ w + ' <end>'\n",
        "  return w\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7aVjjdzujDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "450bd5e4-4397-4d0d-be85-35626c94afc7"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHIFoFmiyVE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#. Remove the accents\n",
        "#. Clean the sentences\n",
        "#. Return word pairs in format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path,num_examples):\n",
        "  lines = io.open(path,encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjhfdR7RyVcC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3fb8eb74-8999-445b-eb46-0a406ee76ba4"
      },
      "source": [
        "en,sp = create_dataset(path_to_file,None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOhaVjJo2RwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2itj_8CyVrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters=''\n",
        "  )\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVOMLjaKyV5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path,num_examples=None):\n",
        "  # Creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, input_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, input_lang_tokenizer, targ_lang_tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iyeMix41dfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LIMIT SIZE OF DATASET\n",
        "num_examples = 30000\n",
        "input_tensor,target_tensor, inp_lang, targ_lang = load_dataset(path_to_file,num_examples)\n",
        "\n",
        "# calculate the max len of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPx5-Qxn5Sis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "febe56b0-48ca-4c9e-e7e6-f29b457196df"
      },
      "source": [
        "# split training and validation sets using 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print([len(l) for l in [input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val]])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[24000, 6000, 24000, 6000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooSdsNKr5S6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print(\"%d --------> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvsIE4Fr7RUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "d74ea27f-ee40-41a6-f2ff-8b03ada125f2"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 --------> <start>\n",
            "28 --------> eso\n",
            "513 --------> suena\n",
            "56 --------> bien\n",
            "3 --------> .\n",
            "2 --------> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 --------> <start>\n",
            "20 --------> that\n",
            "518 --------> sounds\n",
            "107 --------> right\n",
            "3 --------> .\n",
            "2 --------> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrklXLUB7SBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a tf.data dataset\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_5GOpst7R6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d23930ee-df44-4a26-b756-9070da1467e2"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pfkKbR38xHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WRITE THE ENCODER AND DECODER MODEL\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self,vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform')\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygGzYveR8xhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5d1b891-788c-4ad9-cad0-f9c6d2a524dd"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "print('Sample hidden', sample_hidden)\n",
        "\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
        "print('\\n')\n",
        "print('Sample Output->',sample_output)\n",
        "print('\\n')\n",
        "print('sample Hidden->',sample_hidden)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample hidden tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(64, 1024), dtype=float32)\n",
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
            "\n",
            "\n",
            "Sample Output-> tf.Tensor(\n",
            "[[[ 1.47458110e-02 -1.10041304e-03  3.44628538e-03 ...  6.43348973e-03\n",
            "    1.11791147e-02 -9.34091583e-03]\n",
            "  [ 1.13593973e-02  8.13136983e-04 -3.17599624e-03 ...  1.43607648e-03\n",
            "    5.55685023e-03 -1.22272335e-02]\n",
            "  [ 8.73718597e-03  1.40009145e-03 -1.17216902e-02 ... -4.24727378e-03\n",
            "   -5.74014441e-04 -3.12776072e-03]\n",
            "  ...\n",
            "  [-1.82622578e-02  1.03854947e-02  1.24956667e-02 ...  6.93128537e-03\n",
            "    1.02175120e-02 -3.51994019e-03]\n",
            "  [-1.83877572e-02  1.04637071e-02  1.25309909e-02 ...  6.97436836e-03\n",
            "    1.03303837e-02 -3.53985326e-03]\n",
            "  [-1.84680279e-02  1.05035417e-02  1.25450231e-02 ...  6.99867774e-03\n",
            "    1.04045244e-02 -3.56260268e-03]]\n",
            "\n",
            " [[ 1.47458110e-02 -1.10041304e-03  3.44628538e-03 ...  6.43348973e-03\n",
            "    1.11791147e-02 -9.34091583e-03]\n",
            "  [-3.60099319e-03  8.12676270e-03  2.64603705e-06 ...  8.17996729e-03\n",
            "    3.49566713e-03 -7.63868494e-03]\n",
            "  [-2.96486355e-03 -2.86032702e-03  2.56165513e-04 ...  1.55956354e-02\n",
            "   -4.28191945e-03 -3.95582104e-03]\n",
            "  ...\n",
            "  [-1.81377251e-02  1.04072951e-02  1.24435220e-02 ...  6.79376721e-03\n",
            "    1.00829322e-02 -3.59504903e-03]\n",
            "  [-1.83112081e-02  1.04860021e-02  1.25053758e-02 ...  6.89919339e-03\n",
            "    1.02452664e-02 -3.57480068e-03]\n",
            "  [-1.84232797e-02  1.05229998e-02  1.25329224e-02 ...  6.95956219e-03\n",
            "    1.03522651e-02 -3.57690896e-03]]\n",
            "\n",
            " [[ 1.47458110e-02 -1.10041304e-03  3.44628538e-03 ...  6.43348973e-03\n",
            "    1.11791147e-02 -9.34091583e-03]\n",
            "  [ 4.69317101e-03  5.33329789e-03  3.18476534e-03 ...  6.21929718e-03\n",
            "    1.97610329e-03 -1.16851628e-02]\n",
            "  [ 1.01757636e-02  3.58741917e-03  1.47049678e-02 ...  1.32831680e-02\n",
            "   -9.02090513e-04 -1.72517449e-02]\n",
            "  ...\n",
            "  [-1.77903008e-02  1.00070294e-02  1.23473424e-02 ...  6.80955080e-03\n",
            "    9.75738559e-03 -3.89908394e-03]\n",
            "  [-1.80941075e-02  1.02483518e-02  1.24613857e-02 ...  6.90646935e-03\n",
            "    1.00236405e-02 -3.74688674e-03]\n",
            "  [-1.82918571e-02  1.03866160e-02  1.25161903e-02 ...  6.96089631e-03\n",
            "    1.02048367e-02 -3.66877671e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1.47458110e-02 -1.10041304e-03  3.44628538e-03 ...  6.43348973e-03\n",
            "    1.11791147e-02 -9.34091583e-03]\n",
            "  [ 1.84158003e-03  1.09597365e-03  6.86337380e-03 ...  3.39342142e-03\n",
            "    5.64170070e-03  2.71755573e-03]\n",
            "  [ 5.35495952e-03 -1.08576510e-02 -1.68482779e-06 ...  3.27498047e-03\n",
            "    5.88246761e-03 -3.31058912e-03]\n",
            "  ...\n",
            "  [-1.67347211e-02  8.42002966e-03  1.12287486e-02 ...  5.30154211e-03\n",
            "    7.65276095e-03 -3.95123195e-03]\n",
            "  [-1.71693265e-02  9.25900321e-03  1.19473115e-02 ...  6.06632605e-03\n",
            "    8.60106573e-03 -3.77178588e-03]\n",
            "  [-1.75530706e-02  9.81452502e-03  1.22953970e-02 ...  6.49572583e-03\n",
            "    9.25936364e-03 -3.64631577e-03]]\n",
            "\n",
            " [[ 1.47458110e-02 -1.10041304e-03  3.44628538e-03 ...  6.43348973e-03\n",
            "    1.11791147e-02 -9.34091583e-03]\n",
            "  [ 1.40743069e-02  8.54970654e-04  3.24136857e-03 ...  2.58761714e-03\n",
            "    7.40948692e-03 -6.74584601e-03]\n",
            "  [ 1.72559246e-02  2.54515745e-03  1.65498105e-03 ...  2.66812067e-03\n",
            "   -6.12777984e-03 -1.71786908e-03]\n",
            "  ...\n",
            "  [-1.81435328e-02  1.00740688e-02  1.25543838e-02 ...  6.80142222e-03\n",
            "    1.01099163e-02 -3.45271197e-03]\n",
            "  [-1.83140393e-02  1.02536231e-02  1.25805214e-02 ...  6.88247243e-03\n",
            "    1.02693830e-02 -3.48748313e-03]\n",
            "  [-1.84250623e-02  1.03654098e-02  1.25827845e-02 ...  6.93597924e-03\n",
            "    1.03709511e-02 -3.52340681e-03]]\n",
            "\n",
            " [[ 1.47458110e-02 -1.10041304e-03  3.44628538e-03 ...  6.43348973e-03\n",
            "    1.11791147e-02 -9.34091583e-03]\n",
            "  [ 1.40743069e-02  8.54970654e-04  3.24136857e-03 ...  2.58761714e-03\n",
            "    7.40948692e-03 -6.74584601e-03]\n",
            "  [ 2.23616473e-02  6.82189036e-03 -1.17010507e-03 ... -7.93239754e-03\n",
            "    4.88865934e-03 -1.55862840e-02]\n",
            "  ...\n",
            "  [-1.66999307e-02  7.81216891e-03  1.15644149e-02 ...  5.38267149e-03\n",
            "    8.70783813e-03 -3.29158665e-03]\n",
            "  [-1.72422510e-02  8.77549872e-03  1.21926768e-02 ...  5.96957887e-03\n",
            "    9.36556421e-03 -3.26205487e-03]\n",
            "  [-1.76453181e-02  9.43741854e-03  1.24819549e-02 ...  6.34140475e-03\n",
            "    9.80258640e-03 -3.26781231e-03]]], shape=(64, 16, 1024), dtype=float32)\n",
            "\n",
            "\n",
            "sample Hidden-> tf.Tensor(\n",
            "[[-0.01846803  0.01050354  0.01254502 ...  0.00699868  0.01040452\n",
            "  -0.0035626 ]\n",
            " [-0.01842328  0.010523    0.01253292 ...  0.00695956  0.01035227\n",
            "  -0.00357691]\n",
            " [-0.01829186  0.01038662  0.01251619 ...  0.0069609   0.01020484\n",
            "  -0.00366878]\n",
            " ...\n",
            " [-0.01755307  0.00981453  0.0122954  ...  0.00649573  0.00925936\n",
            "  -0.00364632]\n",
            " [-0.01842506  0.01036541  0.01258278 ...  0.00693598  0.01037095\n",
            "  -0.00352341]\n",
            " [-0.01764532  0.00943742  0.01248195 ...  0.0063414   0.00980259\n",
            "  -0.00326781]], shape=(64, 1024), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeEe0nJP8x0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BahdanauAttention\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,  units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size,max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)\n",
        "    ))\n",
        "    # attenton_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score,axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HelK_lMFCQAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5c3e597c-d985-4f2e-8d0f-ee53962e00a5"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DHxpDieCQXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DECODER\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size,embedding_dim,dec_units,batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self,x,hidden,enc_output):\n",
        "    # enc_output.shape == (batch_size,max_length,hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size,1,embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    # Passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1,output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJwbFC6r8yIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5e55f60-a21d-4d17-ea1f-62a47a9c9367"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "sample_decoder_output,_,_ = decoder(tf.random.uniform((BATCH_SIZE,1)),\n",
        "                                    sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHCvnNMCd5Fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTIMIZER AND LOSS FUNCTION\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "def loss_function(real,pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "  loss_ = loss_object(real,pred)\n",
        "\n",
        "  mask = tf.cast(mask,dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGKtgy2Ne7BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wBc_Bnzf1Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ3-cShJf4AV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6066d19b-e3a7-4337-d15f-b87b26baf1a7"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6626\n",
            "Epoch 1 Batch 100 Loss 2.1829\n",
            "Epoch 1 Batch 200 Loss 1.8334\n",
            "Epoch 1 Batch 300 Loss 1.8171\n",
            "Epoch 1 Loss 2.0375\n",
            "Time taken for 1 epoch 92.3559775352478 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4489\n",
            "Epoch 2 Batch 100 Loss 1.3550\n",
            "Epoch 2 Batch 200 Loss 1.5071\n",
            "Epoch 2 Batch 300 Loss 1.2632\n",
            "Epoch 2 Loss 1.4131\n",
            "Time taken for 1 epoch 74.08428716659546 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1852\n",
            "Epoch 3 Batch 100 Loss 1.0946\n",
            "Epoch 3 Batch 200 Loss 0.9818\n",
            "Epoch 3 Batch 300 Loss 0.9772\n",
            "Epoch 3 Loss 1.0039\n",
            "Time taken for 1 epoch 73.46191716194153 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7009\n",
            "Epoch 4 Batch 100 Loss 0.6456\n",
            "Epoch 4 Batch 200 Loss 0.7105\n",
            "Epoch 4 Batch 300 Loss 0.6422\n",
            "Epoch 4 Loss 0.6839\n",
            "Time taken for 1 epoch 73.54629635810852 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4529\n",
            "Epoch 5 Batch 100 Loss 0.4205\n",
            "Epoch 5 Batch 200 Loss 0.4246\n",
            "Epoch 5 Batch 300 Loss 0.4236\n",
            "Epoch 5 Loss 0.4682\n",
            "Time taken for 1 epoch 73.46191501617432 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2991\n",
            "Epoch 6 Batch 100 Loss 0.3047\n",
            "Epoch 6 Batch 200 Loss 0.2709\n",
            "Epoch 6 Batch 300 Loss 0.3213\n",
            "Epoch 6 Loss 0.3246\n",
            "Time taken for 1 epoch 73.91121220588684 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2109\n",
            "Epoch 7 Batch 100 Loss 0.1870\n",
            "Epoch 7 Batch 200 Loss 0.2252\n",
            "Epoch 7 Batch 300 Loss 0.2693\n",
            "Epoch 7 Loss 0.2284\n",
            "Time taken for 1 epoch 73.26953864097595 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1615\n",
            "Epoch 8 Batch 100 Loss 0.1299\n",
            "Epoch 8 Batch 200 Loss 0.2226\n",
            "Epoch 8 Batch 300 Loss 0.2036\n",
            "Epoch 8 Loss 0.1698\n",
            "Time taken for 1 epoch 74.01563787460327 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0830\n",
            "Epoch 9 Batch 100 Loss 0.1313\n",
            "Epoch 9 Batch 200 Loss 0.1196\n",
            "Epoch 9 Batch 300 Loss 0.1821\n",
            "Epoch 9 Loss 0.1329\n",
            "Time taken for 1 epoch 73.66969990730286 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1009\n",
            "Epoch 10 Batch 100 Loss 0.0922\n",
            "Epoch 10 Batch 200 Loss 0.1131\n",
            "Epoch 10 Batch 300 Loss 0.0927\n",
            "Epoch 10 Loss 0.1070\n",
            "Time taken for 1 epoch 73.70245742797852 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrunGSbPf-9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osw7cUuVf9nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bonJ_VdNgD4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4bbUxPmgGlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "decaa2fc-eecf-4b96-9062-2324550b257a"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3be09afcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN6Rz3zugGc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "4ae8c9e2-8035-4682-cd97-e2bb37b38b0c"
      },
      "source": [
        "# TRANSLATE\n",
        "translate(u'hace mucho frio aqui.')\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAJwCAYAAAC08grWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}