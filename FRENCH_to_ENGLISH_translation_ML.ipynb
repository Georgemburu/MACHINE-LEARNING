{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FRENCH to ENGLISH translation ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Georgemburu/MACHINE-LEARNING/blob/master/FRENCH_to_ENGLISH_translation_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe-IvT3WwKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP6Vxv2awQIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://www.manythings.org/anki/fra-eng.zip\n",
        "# OVERVIEW\n",
        "# (FRENCH to ENGLISH ) -> translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmn2abOdwdsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, absolute_import, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import unicodedata\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p216pSydweHI",
        "colab_type": "code",
        "outputId": "fe4aeca4-6a18-46dd-db66-b9381882389a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file('fra-eng.zip',\n",
        "                                      origin='http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip',\n",
        "                                      extract=True)\n",
        "path_to_file = os.path.dirname(path_to_zip)+'/fra.txt'\n",
        "print(path_to_file)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/fra.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al4DGNt0weCX",
        "colab_type": "code",
        "outputId": "51fbdb90-75cd-4aff-8945-f7a4999838eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "pd.read_csv(path_to_file, delimiter='\\t')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Go.</th>\n",
              "      <th>Va !</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Coursâ€¯!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courezâ€¯!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ã‡a alorsâ€¯!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167124</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167125</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous dÃ©courage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167126</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167127</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaÃ®t pas vos antÃ©cÃ©dent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167128</th>\n",
              "      <td>It may be impossible to get a completely error...</td>\n",
              "      <td>Il est peut-Ãªtre impossible d'obtenir un Corpu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>167129 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      Go.                                               Va !\n",
              "0                                                     Hi.                                            Salut !\n",
              "1                                                    Run!                                            Coursâ€¯!\n",
              "2                                                    Run!                                           Courezâ€¯!\n",
              "3                                                    Who?                                              Qui ?\n",
              "4                                                    Wow!                                         Ã‡a alorsâ€¯!\n",
              "...                                                   ...                                                ...\n",
              "167124  A carbon footprint is the amount of carbon dio...  Une empreinte carbone est la somme de pollutio...\n",
              "167125  Death is something that we're often discourage...  La mort est une chose qu'on nous dÃ©courage sou...\n",
              "167126  Since there are usually multiple websites on a...  Puisqu'il y a de multiples sites web sur chaqu...\n",
              "167127  If someone who doesn't know your background sa...  Si quelqu'un qui ne connaÃ®t pas vos antÃ©cÃ©dent...\n",
              "167128  It may be impossible to get a completely error...  Il est peut-Ãªtre impossible d'obtenir un Corpu...\n",
              "\n",
              "[167129 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaCX62uhwd8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s)\n",
        "    if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQuzD1_UymNJ",
        "colab_type": "code",
        "outputId": "ba42d751-3431-45cd-91e6-9dd76c54a8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "unicodedata.normalize('NFD','Si quelqu\\'un qui ne connaÃ®t')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Si quelqu'un qui ne connaiÌ‚t\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYhRB5OUymgu",
        "colab_type": "code",
        "outputId": "964ac566-b008-4e36-e3e3-2937605cf2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "for i in 'Si quelqu\\'un qui ne connaÃ®t +â€£ ðŸ˜‹ â—ŒÌ¡ k ` Â¬ ^':\n",
        "  c = unicodedata.category(i)\n",
        "  print(i,'-->',c)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S --> Lu\n",
            "i --> Ll\n",
            "  --> Zs\n",
            "q --> Ll\n",
            "u --> Ll\n",
            "e --> Ll\n",
            "l --> Ll\n",
            "q --> Ll\n",
            "u --> Ll\n",
            "' --> Po\n",
            "u --> Ll\n",
            "n --> Ll\n",
            "  --> Zs\n",
            "q --> Ll\n",
            "u --> Ll\n",
            "i --> Ll\n",
            "  --> Zs\n",
            "n --> Ll\n",
            "e --> Ll\n",
            "  --> Zs\n",
            "c --> Ll\n",
            "o --> Ll\n",
            "n --> Ll\n",
            "n --> Ll\n",
            "a --> Ll\n",
            "Ã® --> Ll\n",
            "t --> Ll\n",
            "  --> Zs\n",
            "+ --> Sm\n",
            "â€£ --> Po\n",
            "  --> Zs\n",
            "ðŸ˜‹ --> So\n",
            "  --> Zs\n",
            "â—Œ --> So\n",
            "Ì¡ --> Mn\n",
            "  --> Zs\n",
            "k --> Ll\n",
            "  --> Zs\n",
            "` --> Sk\n",
            "  --> Zs\n",
            "Â¬ --> Sm\n",
            "  --> Zs\n",
            "^ --> Sk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFGUaODh12Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  # create a space between a word and the punctuation\n",
        "  w = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", w)\n",
        "\n",
        "  w = w.rstrip().strip()\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYK-IL4R4trv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f2ce806-c7d9-4608-e244-4c7b630462b9"
      },
      "source": [
        "fra_sentence = u\"Il est peut-Ãªtre impossible d'obtenir un Corpu\"\n",
        "print(preprocess_sentence(fra_sentence))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> il est peut etre impossible d obtenir un corpu <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BaD22LG6D7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t') ] for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS6qKlkt6D1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "33aa9770-de0f-4b1f-bbb5-324eee78020c"
      },
      "source": [
        "en, fra = create_dataset(path_to_file,None)\n",
        "print(en[-1])\n",
        "print(fra[-1])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> it may be impossible to get a completely error free corpus due to the nature of this kind of collaborative effort . however , if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning , we might be able to minimize errors . <end>\n",
            "<start> il est peut etre impossible d obtenir un corpus completement denue de fautes , etant donnee la nature de ce type d entreprise collaborative . cependant , si nous encourageons les membres a produire des phrases dans leurs propres langues plutot que d experimenter dans les langues qu ils apprennent , nous pourrions etre en mesure de reduire les erreurs . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h45j0fCb6Dpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V96vFO827UAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters=''\n",
        "  )\n",
        "  # fit vocabulary to the Tokenizer\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  # tokenize\n",
        "  tensors = lang_tokenizer.texts_to_sequences(lang)\n",
        "  # Pad the tokens\n",
        "  tensors = tf.keras.preprocessing.sequence.pad_sequences(tensors, padding='post')\n",
        "  return tensors, lang_tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdXR3PxR7T7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path,num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path,num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDxX-0CN7T2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file,num_examples)\n",
        "# calculate the max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdBer9pk7Tvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dab6831e-9710-404a-941f-5bf9db6138f0"
      },
      "source": [
        "print('max_length_targ',max_length_targ)\n",
        "print('max_length_inp',max_length_inp)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length_targ 10\n",
            "max_length_inp 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C8Mgeon7Tkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98fdd5c8-119d-463e-8449-77eefe8922f1"
      },
      "source": [
        "# creating training and validation set\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor,target_tensor)\n",
        "# show length\n",
        "print([len(l) for l in [input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val]])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22500, 7500, 22500, 7500]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDxB6ZNhB9I6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t !=0:\n",
        "      print(t, '-----> ', lang.index_word[t])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJtLfyOgB_gz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "97dd54b7-906d-4780-a1b3-ca5ef9843831"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----->  <start>\n",
            "115 ----->  soyez\n",
            "3132 ----->  justes\n",
            "12 ----->  !\n",
            "2 ----->  <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----->  <start>\n",
            "36 ----->  be\n",
            "553 ----->  fair\n",
            "3 ----->  .\n",
            "2 ----->  <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18XSj8y5CNLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a tf.data Dataset\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "\n",
        "dataset_TRAIN = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset_TRAIN = dataset_TRAIN.batch(BATCH_SIZE, drop_remainder=True)\n",
        "# dataset_val = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL6AujjFCNlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79c5785d-2397-4bd1-991e-9f24bcb2a156"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset_TRAIN))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 17]), TensorShape([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q4uveCaCN6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "cfda3288-648c-42a9-8f72-9b7c84cc5fe4"
      },
      "source": [
        "# Write the encoder decoder\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
        "\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 17, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 17, 1)\n",
            "Decoder output shape: (batch_size, vocab size) (64, 4442)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfxGnrv4CN17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer and loss function\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none'\n",
        ")\n",
        "\n",
        "def loss_function(real,pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "  loss_ = loss_object(real,pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVpgZQ8aIM0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4b9ca935-5f0f-446e-c676-dc4780e71d5f"
      },
      "source": [
        "matx = np.array([[3,0,3],[0,3,0]])\n",
        "matx = tf.math.equal(matx,3)\n",
        "matx"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=649, shape=(2, 3), dtype=bool, numpy=\n",
              "array([[ True, False,  True],\n",
              "       [False,  True, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCJqNyM5CNwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e2c32ec9-d1c2-4bba-db40-9d9e8d8d2279"
      },
      "source": [
        "matx = tf.math.logical_not(matx)\n",
        "matx"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=650, shape=(2, 3), dtype=bool, numpy=\n",
              "array([[False,  True, False],\n",
              "       [ True, False,  True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMjSoIUtIm7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "162a5337-3f76-4039-83e2-14351e8a3168"
      },
      "source": [
        "tf.cast(matx,dtype='float32')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=651, shape=(2, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 0.],\n",
              "       [1., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oHRiBxOJ8FK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CHECKPOINTS(OBJECT-bASED sAVING)\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah8b4wC4J7_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1,targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden,_ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:,t], predictions)\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:,t],1)\n",
        "\n",
        "  batch_loss = (loss/int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyjHKbqUOk5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "937R54G-J731",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cceb5b9-5908-4c41-f2d9-da4b769e0609"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  for (batch, (inp, targ)) in  enumerate(dataset_TRAIN.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if(batch % 100 == 0):\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving checkpoints\n",
        "  if (epoch +1) %2==0:\n",
        "    checkpoint.save(file_prefix= checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7046\n",
            "Epoch 1 Batch 100 Loss 2.2922\n",
            "Epoch 1 Batch 200 Loss 1.9275\n",
            "Epoch 1 Batch 300 Loss 1.6391\n",
            "Epoch 1 Loss 2.1140\n",
            "Time taken for 1 epoch 25.72206950187683 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.6327\n",
            "Epoch 2 Batch 100 Loss 1.5819\n",
            "Epoch 2 Batch 200 Loss 1.3853\n",
            "Epoch 2 Batch 300 Loss 1.2316\n",
            "Epoch 2 Loss 1.4015\n",
            "Time taken for 1 epoch 26.138407468795776 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0482\n",
            "Epoch 3 Batch 100 Loss 1.1068\n",
            "Epoch 3 Batch 200 Loss 0.8849\n",
            "Epoch 3 Batch 300 Loss 0.8987\n",
            "Epoch 3 Loss 0.9706\n",
            "Time taken for 1 epoch 24.94402837753296 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6930\n",
            "Epoch 4 Batch 100 Loss 0.7305\n",
            "Epoch 4 Batch 200 Loss 0.6966\n",
            "Epoch 4 Batch 300 Loss 0.5500\n",
            "Epoch 4 Loss 0.6473\n",
            "Time taken for 1 epoch 25.052005529403687 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4496\n",
            "Epoch 5 Batch 100 Loss 0.4481\n",
            "Epoch 5 Batch 200 Loss 0.3763\n",
            "Epoch 5 Batch 300 Loss 0.4231\n",
            "Epoch 5 Loss 0.4299\n",
            "Time taken for 1 epoch 24.6175217628479 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2658\n",
            "Epoch 6 Batch 100 Loss 0.3238\n",
            "Epoch 6 Batch 200 Loss 0.2559\n",
            "Epoch 6 Batch 300 Loss 0.2775\n",
            "Epoch 6 Loss 0.2944\n",
            "Time taken for 1 epoch 25.453901052474976 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1675\n",
            "Epoch 7 Batch 100 Loss 0.2322\n",
            "Epoch 7 Batch 200 Loss 0.2024\n",
            "Epoch 7 Batch 300 Loss 0.2077\n",
            "Epoch 7 Loss 0.2096\n",
            "Time taken for 1 epoch 24.99775218963623 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1183\n",
            "Epoch 8 Batch 100 Loss 0.1294\n",
            "Epoch 8 Batch 200 Loss 0.1298\n",
            "Epoch 8 Batch 300 Loss 0.1836\n",
            "Epoch 8 Loss 0.1559\n",
            "Time taken for 1 epoch 25.78692126274109 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1769\n",
            "Epoch 9 Batch 100 Loss 0.0953\n",
            "Epoch 9 Batch 200 Loss 0.1434\n",
            "Epoch 9 Batch 300 Loss 0.1211\n",
            "Epoch 9 Loss 0.1229\n",
            "Time taken for 1 epoch 25.03109359741211 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1083\n",
            "Epoch 10 Batch 100 Loss 0.0852\n",
            "Epoch 10 Batch 200 Loss 0.1066\n",
            "Epoch 10 Batch 300 Loss 0.1010\n",
            "Epoch 10 Loss 0.1060\n",
            "Time taken for 1 epoch 25.695178508758545 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQwAcrTRJ7xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRANSLATE\n",
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in str(sentence).split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B6vBflyUf_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBFzy0u2T6_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzqcXVt0T95N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dubghn21T9vX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b486927b-c325-4d83-aac7-68c12089fae4"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5b69549cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyfgTLwZUBMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "b1bb98b7-637f-4328-df5b-1201babada74"
      },
      "source": [
        "translate(u'je suis un bon garÃ§on')\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> je suis un bon garcon <end>\n",
            "Predicted translation: i m a good boy . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAJwCAYAAAC08grWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0NwjSf/+4aeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5UGKNlsUA_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}