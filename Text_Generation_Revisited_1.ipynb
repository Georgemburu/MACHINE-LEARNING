{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Revisited 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Georgemburu/MACHINE-LEARNING/blob/master/Text_Generation_Revisited_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihkCNeCMx2lB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07d2d30f-4aca-4cb6-b5fa-3e311007f462"
      },
      "source": [
        "%tensorflow_version 2.x\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-6sXKLdxlpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, print_function, unicode_literals,division\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os \n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Yut8NPyFNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3a8dfb6e-7a4a-4644-8bde-717976167db5"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file(\n",
        "    'shakespeare.txt',\n",
        "    origin='https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65QN8v8SyP1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2110ca53-2d62-49dd-c610-5454677a5d28"
      },
      "source": [
        "# Read the data\n",
        "text = open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print('length of text:',len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of text: 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Eec73-MycOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "53aa2844-092a-4b42-ba84-7c17e683e04a"
      },
      "source": [
        "# Take a look at some text\n",
        "print(text[:250])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqT7TavCycqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f45650f9-24f9-444a-c038-7b239799d554"
      },
      "source": [
        "# Creat a vocab\n",
        "vocab =sorted(set(text))\n",
        "print('Vocab length:',len(vocab))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab length: 65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58We7e0wy0ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process The Text\n",
        "# 1. Vectorize the text\n",
        "char2idx = {c:i for i,c in enumerate(vocab)}\n",
        "idx2char = {i:c for i,c in enumerate(vocab)}\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5-4Qvrqyz9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a3280961-7082-4a2a-dc3d-26bcdef439f5"
      },
      "source": [
        "text_as_int[:250]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
              "       44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39,\n",
              "       52, 63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1,\n",
              "       51, 43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31,\n",
              "       54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56,\n",
              "       57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39,\n",
              "       56, 43,  1, 39, 50, 50,  1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56,\n",
              "       39, 58, 46, 43, 56,  1, 58, 53,  1, 42, 47, 43,  1, 58, 46, 39, 52,\n",
              "        1, 58, 53,  1, 44, 39, 51, 47, 57, 46, 12,  0,  0, 13, 50, 50, 10,\n",
              "        0, 30, 43, 57, 53, 50, 60, 43, 42,  8,  1, 56, 43, 57, 53, 50, 60,\n",
              "       43, 42,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43,\n",
              "       52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63, 53, 59,  1, 49, 52, 53,\n",
              "       61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41, 47, 59, 57,  1, 47,\n",
              "       57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,  1, 58, 53,  1,\n",
              "       58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghDbc4zFzd8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to decode text tensor\n",
        "def decode_sentence(sentence):\n",
        "  return ''.join(idx2char[c] for c in sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCSJ8fUx0GZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to encode sentence\n",
        "def encode_sentence(sentence):\n",
        "  return np.array([char2idx[c] for c in sentence])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbDAnyLUzwT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bb75fc70-ad81-463b-8bcb-a5bedb8d944d"
      },
      "source": [
        "decode_sentence(text_as_int[:250])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhZGkWX70cPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "6da215eb-22f9-48eb-9358-23c9e6b10b93"
      },
      "source": [
        "encode_sentence(decode_sentence(text_as_int[:250]))== text_as_int[:250]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqHAA8UE01nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e7a56605-58c7-432b-daa8-cf628a176882"
      },
      "source": [
        "# PREDICTION TASK\n",
        "seq_length = 100\n",
        "examples_per_epochs = len(text)//(seq_length+1)\n",
        "# create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phcl7mjv1xiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "af1681f7-aa73-4e2f-db51-ef5c0dd6dfed"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(decode_sentence(item.numpy()))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQOJFyRt2-Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split functions \n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-9r3wT-3P5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "d3053a85-4e89-46d0-be5f-9c2fe7d5476a"
      },
      "source": [
        "for inp, targ in dataset.take(1):\n",
        "  print('Inp:->',inp)\n",
        "  print('Targ:->',targ)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inp:-> tf.Tensor(\n",
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59], shape=(100,), dtype=int64)\n",
            "Targ:-> tf.Tensor(\n",
            "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
            " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
            " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
            "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
            " 37 53 59  1], shape=(100,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtlOodaD3PzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d71c0b3b-371d-4b26-be28-652327844f68"
      },
      "source": [
        "# Create training Batches\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR-_Vf5l3PnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BUILD THE MODEL\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,embedding_dim,\n",
        "                                batch_input_shape=[batch_size,None]),\n",
        "      tf.keras.layers.GRU(rnn_units,\n",
        "                          return_sequences=True,\n",
        "                          stateful=True,\n",
        "                          recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra0-2ZV65KNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e81521-fef1-4fb2-b1ba-1e57274d1524"
      },
      "source": [
        "# Test the model\n",
        "for input_example_batch, targ_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions)\n",
        "  print(example_batch_predictions.shape)\n",
        "  print('batch_size, sequence_length,vocab_size')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 1.94497034e-02 -9.27703269e-03 -1.53801795e-02 ... -6.97805081e-04\n",
            "   -8.65260884e-03 -1.17516657e-02]\n",
            "  [ 8.53184145e-03 -5.49715152e-03 -1.09994942e-02 ... -6.37609977e-04\n",
            "    1.05899666e-03 -1.44618601e-02]\n",
            "  [ 2.51820032e-03  6.09260052e-04 -6.12176256e-04 ... -3.81841278e-03\n",
            "    4.13145218e-03 -1.68056376e-02]\n",
            "  ...\n",
            "  [-2.05953214e-02 -3.73741984e-03  1.95849333e-02 ... -1.54804438e-05\n",
            "    8.80505331e-03 -4.41480055e-03]\n",
            "  [-6.89258240e-03 -2.89372448e-03  1.63163710e-02 ...  1.80321536e-03\n",
            "    1.54160783e-02 -1.10499114e-02]\n",
            "  [-8.89282115e-03  1.82306720e-03  1.25508392e-02 ... -3.46512953e-03\n",
            "    1.22613534e-02 -1.71570070e-02]]\n",
            "\n",
            " [[ 6.42162003e-03  3.61999497e-03  1.44417379e-02 ...  8.24582018e-03\n",
            "    8.74631666e-03  1.27377445e-02]\n",
            "  [ 6.95883855e-03  1.59812439e-02  1.79161653e-02 ...  6.57138368e-03\n",
            "    1.60858706e-02  2.18497007e-04]\n",
            "  [ 4.26428858e-04  6.16571121e-03  1.49651598e-02 ...  5.12869284e-03\n",
            "    2.32984917e-03  6.96100155e-03]\n",
            "  ...\n",
            "  [ 1.19029228e-02  1.00330375e-02  5.18323155e-03 ... -5.82459569e-03\n",
            "    7.48658832e-03 -3.61760100e-03]\n",
            "  [ 2.90325307e-03  6.19201036e-03  9.92758572e-03 ... -5.20903897e-03\n",
            "    4.88228537e-03 -1.14977621e-02]\n",
            "  [ 1.47003692e-03 -2.46143388e-03  1.83921829e-02 ... -1.56427175e-02\n",
            "   -5.10023814e-03 -1.93168432e-03]]\n",
            "\n",
            " [[ 9.21100727e-04 -5.74126421e-03  1.07842218e-02 ... -1.66900158e-02\n",
            "   -7.06158625e-03  4.28656954e-03]\n",
            "  [-3.01907933e-03 -1.00199059e-02  1.70096494e-02 ... -1.73669886e-02\n",
            "    3.05374060e-03 -2.37481995e-03]\n",
            "  [-6.72765891e-04  8.95561464e-03  1.35183632e-02 ... -1.91859938e-02\n",
            "    1.07972417e-02  4.69806045e-03]\n",
            "  ...\n",
            "  [-2.66230665e-03  5.61779691e-03  9.92780272e-03 ...  8.84476118e-04\n",
            "    3.01230163e-03  3.61394603e-03]\n",
            "  [-3.18166683e-03  6.25202060e-03  1.00832302e-02 ... -4.57267743e-03\n",
            "    2.03778315e-03 -6.64545596e-03]\n",
            "  [ 8.83689150e-04  4.98520304e-03  2.91604595e-03 ...  8.56948737e-03\n",
            "    7.93220289e-03 -3.60024394e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 2.77243485e-03  1.04892934e-02 -7.64392782e-04 ...  9.17368289e-03\n",
            "    8.64332169e-03  5.06108627e-03]\n",
            "  [ 6.08967803e-03  5.31901326e-03  2.87650758e-03 ...  7.40326103e-03\n",
            "    1.05004422e-02  2.47335993e-06]\n",
            "  [ 2.65584653e-03  2.62079015e-03 -4.58322465e-03 ... -7.93970749e-03\n",
            "    1.00988988e-02 -3.14584840e-03]\n",
            "  ...\n",
            "  [-2.69429805e-03 -9.47849359e-04  1.66068822e-02 ... -1.49942711e-02\n",
            "   -5.18508255e-03 -1.56341400e-03]\n",
            "  [-5.45258820e-03  4.93679009e-03  3.00738979e-02 ... -1.07827634e-02\n",
            "    6.07309537e-03  6.82070991e-03]\n",
            "  [-5.09102317e-03 -3.20215733e-03  2.06357297e-02 ... -2.22518109e-04\n",
            "    4.88566700e-04  1.07859820e-02]]\n",
            "\n",
            " [[-2.83588422e-03  2.40770541e-03  4.76273522e-03 ... -3.45160486e-03\n",
            "    2.14421423e-03 -8.25949293e-03]\n",
            "  [-1.23569486e-03 -3.89783620e-03  1.43262111e-02 ... -1.54643711e-02\n",
            "   -6.19642623e-03  5.09713776e-04]\n",
            "  [-9.56989825e-05 -3.12779285e-03  3.49403126e-03 ...  2.17080349e-03\n",
            "    5.83676482e-03  1.71278196e-04]\n",
            "  ...\n",
            "  [ 4.89527173e-03  1.00069717e-02  6.41725166e-03 ...  1.99255883e-03\n",
            "    1.19930692e-02  7.52444146e-03]\n",
            "  [ 2.34551001e-02 -3.06304707e-03 -1.34965423e-02 ...  1.19239721e-03\n",
            "   -3.01602669e-03 -3.91894858e-03]\n",
            "  [ 1.64710879e-02  1.14758173e-02 -1.17617601e-03 ... -7.27766007e-03\n",
            "    7.48643838e-03  5.25213266e-03]]\n",
            "\n",
            " [[-3.35687422e-03  2.68774573e-03 -4.62030107e-03 ...  3.55863944e-04\n",
            "    3.01054306e-03 -6.91996934e-03]\n",
            "  [-4.48003504e-03  6.55277260e-03  1.85129698e-03 ... -2.93172826e-03\n",
            "    3.78024438e-03 -1.22723337e-02]\n",
            "  [-3.13363038e-03  1.33603462e-03  5.42041473e-03 ...  3.68316332e-03\n",
            "   -9.37311910e-04  2.34926911e-03]\n",
            "  ...\n",
            "  [ 3.22826160e-03  1.56207681e-02  1.02457209e-02 ...  4.05383762e-03\n",
            "    1.74609460e-02 -6.29277248e-03]\n",
            "  [-3.71931982e-03  1.27534429e-02  1.08194305e-02 ... -1.80835649e-03\n",
            "    9.50170681e-03 -1.30069898e-02]\n",
            "  [-1.16035203e-03  1.89454518e-02  6.30715489e-03 ...  1.10481139e-02\n",
            "    1.27300527e-02 -2.39134370e-03]]], shape=(64, 100, 65), dtype=float32)\n",
            "(64, 100, 65)\n",
            "batch_size, sequence_length,vocab_size\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJYFQOE3502n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "d05e6986-ceef-40c9-b2ae-5782f2e5ea37"
      },
      "source": [
        "example_batch_predictions[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 65), dtype=float32, numpy=\n",
              "array([[ 1.94497034e-02, -9.27703269e-03, -1.53801795e-02, ...,\n",
              "        -6.97805081e-04, -8.65260884e-03, -1.17516657e-02],\n",
              "       [ 8.53184145e-03, -5.49715152e-03, -1.09994942e-02, ...,\n",
              "        -6.37609977e-04,  1.05899666e-03, -1.44618601e-02],\n",
              "       [ 2.51820032e-03,  6.09260052e-04, -6.12176256e-04, ...,\n",
              "        -3.81841278e-03,  4.13145218e-03, -1.68056376e-02],\n",
              "       ...,\n",
              "       [-2.05953214e-02, -3.73741984e-03,  1.95849333e-02, ...,\n",
              "        -1.54804438e-05,  8.80505331e-03, -4.41480055e-03],\n",
              "       [-6.89258240e-03, -2.89372448e-03,  1.63163710e-02, ...,\n",
              "         1.80321536e-03,  1.54160783e-02, -1.10499114e-02],\n",
              "       [-8.89282115e-03,  1.82306720e-03,  1.25508392e-02, ...,\n",
              "        -3.46512953e-03,  1.22613534e-02, -1.71570070e-02]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW69hc7s6ICl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "a37dfc92-ef42-4ec4-c91c-2bf61ad797bb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA2uZeis6NJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a73d364d-682d-475f-aa20-72080829c251"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 47, 37, 64, 57, 51, 48, 20, 37, 63, 42, 14, 34, 51, 23, 64, 44,\n",
              "       31, 35,  4, 49, 59, 45, 41, 12, 40, 57, 25, 33, 50, 49, 33, 32,  3,\n",
              "        3,  8, 16,  9, 11, 30, 64, 23, 57, 61, 27, 35, 57, 27, 48, 59, 22,\n",
              "       20, 19, 56, 52, 52, 45, 63, 35, 58, 25, 51, 11, 53, 14, 23, 31, 38,\n",
              "       14, 44, 37, 13, 35,  8, 51,  5, 47, 60,  5,  7, 35, 14, 48, 59,  5,\n",
              "       27, 50, 25, 38, 26, 46, 64, 43, 15, 55, 11, 50, 17, 44, 61])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP9TtqWa8W-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ee2feee-e528-4af2-e704-a9d1edb3562d"
      },
      "source": [
        "sampled_indices.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm4Vtgyv6Rqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "16da0a18-68c2-4631-cc0d-32ca7c2ac994"
      },
      "source": [
        "# decode those to see the prediction from untrained model\n",
        "decode_sentence(sampled_indices)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"$iYzsmjHYydBVmKzfSW&kugc?bsMUlkUT$$.D3;RzKswOWsOjuJHGrnngyWtMm;oBKSZBfYAW.m'iv'-WBju'OlMZNhzeCq;lEfw\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt1t-yrB6Nwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bb1b5828-1bef-4e27-8ce2-17c1687ebc8a"
      },
      "source": [
        "# Train the model\n",
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(targ_example_batch, example_batch_predictions)\n",
        "print('Pediction shape: ',example_batch_loss.shape)\n",
        "print('scalar_loss:  ', example_batch_loss.numpy().mean())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pediction shape:  (64, 100)\n",
            "scalar_loss:   4.173311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxj8SFlA8taF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlkwH8SQ8z4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure checkpoints\n",
        "checkpoints_dir = './trainig_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoints_dir,'chkpt_{epoch}')\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUyeJUDg9ryg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "55dd37b5-242e-475f-e312-21453ebab76b"
      },
      "source": [
        "# Execute the training\n",
        "EPOCHS = 10\n",
        "history = model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 172 steps\n",
            "Epoch 1/10\n",
            "172/172 [==============================] - 13s 77ms/step - loss: 2.7166\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.9772\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.7040\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 1.5522\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.4612\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 12s 68ms/step - loss: 1.4004\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.3541\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 70ms/step - loss: 1.3138\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.2797\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 12s 69ms/step - loss: 1.2467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V-fV_e8-Dam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "89521db5-007e-4c4d-9e48-88051cbd5822"
      },
      "source": [
        "# Restore the latest checkpoint\n",
        "# GENERATE TEXT\n",
        "model = build_model(\n",
        "    vocab_size,\n",
        "    embedding_dim,\n",
        "    rnn_units,\n",
        "    batch_size=1\n",
        ")\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoints_dir))\n",
        "model.build(tf.TensorShape([1,None]))\n",
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vwa5pPu-0fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model,start_string):\n",
        "  num_generate = 1000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    # remove the batch dimention\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "  return (start_string +''.join(text_generated))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km1rxClZAZfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "2eaf54bd-16d4-48c2-eb30-11189303e068"
      },
      "source": [
        "print(generate_text(model, start_string=u\"ROMEO: \"))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: God s,\n",
            "As it is war have made for the honour of his phording Richard Scend,\n",
            "Aumored over my life for leave to sctre.\n",
            "\n",
            "TRANIO:\n",
            "Hair for his form, eyes.\n",
            "Grace as fair sorrow, before me love? thou\n",
            "art a guilt; his purpose may be short betimes\n",
            "Upon his body, in one three-like gentleman in\n",
            "this scletence as those knaves as thoughts to praised, I do command.\n",
            "\n",
            "PETRUCHIO:\n",
            "It is a maid words, Tappine and quicklawam, and none;\n",
            "Let them I make you falling to keep agree.\n",
            "\n",
            "First Gentleman:\n",
            "Shall I see this shophers; would it is ready to him.\n",
            "Nor now, good man! let's apoll and Dar Helves share, he had left a\n",
            "Nave hamina, in company, carrilming bleeds with nail:\n",
            "We came utouche you to hair another's traungoon, and like itself,\n",
            "Who had be rathers cilled up the terms of her,\n",
            "Bloody treed.\n",
            "\n",
            "Second Citizen:\n",
            "You do, my son! O mercy more, no more! I say I see the crown.\n",
            "\n",
            "KING HENRY VI\n",
            "\n",
            "WARWICK:\n",
            "\n",
            "TRANIO:\n",
            "Master, my soul\n",
            "Bole complexerace.\n",
            "\n",
            "BIANCA:\n",
            "Was ever medown against the malmanded arms.'\n",
            "\n",
            "FRIAR TH:\n",
            "Musi\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}